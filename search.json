[{"path":"https://sdaume.github.io/srcquantcourse/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Stefan Daume Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example: Topic modelling Covid preprints","text":"example topic modelling analysis using Structural Topic Model (STM) (Roberts, Stewart, Tingley 2019) explore subset bioRxiv medRxiv preprints covering research related Covid-19. medRxiv website actually provides access dedicated collection preprints medRxix bioRxiv covering COVID-19 SARS-CoV-2. however work whole preprint collection create subset using keyword matching. Note analysis intended illustrate method topic modeling. complete analysis sample preprints detailed like feature larger number topics. document assumes familiarity Structural Topic Modeling (STM). Please consult stm package vignette (Roberts, Stewart, Tingley 2019) background.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"getting-the-document-data","dir":"Articles","previous_headings":"","what":"Getting the document data","title":"Example: Topic modelling Covid preprints","text":"bioRxiv medRxiv servers provide API access retrieve preprint meta-data. One option access API use medrxivr package. code snippet example collect bioRxiv preprint meta-data year 2015. package setup support exploring different thematic preprint subsets assumes usage preprints servers published 2013 2023. data can shared package usage API terms bioRxiv/medRxiv permit redistribution rehosting complete data; therefore package provides scripts collect clean data order replicate analysis (check /data-raw package repository). documented examples assume obtained data created local copy replication analyses. code allow . NOTE time writing returned dataset 365526 records. Retrieving data take several hours. replicating analysis like use bioRxiv/medRxiv API responsibly. Consider collecting smaller datasets (example shown example require preprints 2020 2023). Alternatively, use bulk snapshot detailed . addition 15 meta-data variables returned via API code adds server variable indicate origin preprint. important variable examples shown .","code":"library(medrxivr)  biorxiv_raw <- mx_api_content(server = \"biorxiv\",                               from_date = \"2015-12-01\",                               to_date = \"2015-12-31\") library(dplyr) library(medrxivr)  # get publications from medRxiv and bioRxiv pubs_biorxiv_raw <- medrxivr::mx_api_content(server = \"biorxiv\",                                              #from_date = \"2019-01-01\",                                              to_date = \"2023-12-31\")  pubs_medrxiv_raw <- medrxivr::mx_api_content(server = \"medrxiv\",                                              #from_date = \"2019-01-01\",                                              to_date = \"2023-12-31\")  pubs_biorxiv_raw <- pubs_biorxiv_raw %>%   mutate(server = \"biorxiv\")  pubs_medrxiv_raw <- pubs_medrxiv_raw %>%   mutate(server = \"medrxiv\")  preprints_raw <- dplyr::bind_rows(pubs_biorxiv_raw, pubs_medrxiv_raw)  save(preprints_raw, file = \"./data-raw/preprints_raw.Rdata\")"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"cleaning-filtering-and-annotating-the-data","dir":"Articles","previous_headings":"","what":"Cleaning, filtering and annotating the data","title":"Example: Topic modelling Covid preprints","text":"first step raw preprint data cleaned. Specifically, want retain one unique record per preprint, multiple versions unique doi may exist. retain latest version per DOI also ensure duplicate dois. crucial need unique identifier document want include topic modelling. Next annotate data additional variables, specifically want reduce publication date publication year, add additional variable is_published, inferred published variable. latter provides DOI journal preprint published peer review. also limit data preprints 2020 2023 (analysis Covid topics preprints prior 2020 relevant), retain variables may want explore document covariates, .e. document properties potentially influence prevalence topics. Finally, define keywords reduce preprint set preprints contain one keywords either title abstract, resulting subset 29692 publications.","code":"library(dplyr)  preprints_cleaned <- preprints_raw %>%   group_by(doi) %>%   filter(version == max(version)) %>%   ungroup() %>%   distinct(doi, .keep_all = TRUE) preprints <- preprints_cleaned %>%   mutate(published = stringr::str_trim(published)) %>%   mutate(published = na_if(published, \"NA\")) %>%   mutate(is_published = as.numeric(!is.na(published))) %>%   mutate(is_published = case_when(is_published == 1 ~ \"published\",                                   is_published == 0 ~ \"not published\",                                   TRUE ~ \"undefined\")) %>%   mutate(year = lubridate::year(date)) %>%   filter(year >= 2020 & year <= 2023) %>%    select(doi, server, title, abstract, date, year, version, is_published) library(stringr)  keywords <- c(\"sars-cov\", \"covid\")  search_pattern <- stringr::regex(paste(keywords, collapse = \"|\"),                                   ignore_case = TRUE)  covid_preprints <- preprints %>%   filter(stringr::str_detect(title, pattern = search_pattern) |            stringr::str_detect(abstract, pattern = search_pattern))"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"preparing-and-preprocessing-the-documents-for-text-analysis","dir":"Articles","previous_headings":"","what":"Preparing and preprocessing the documents for text analysis","title":"Example: Topic modelling Covid preprints","text":"order analyze preprints stm package need create representation documents document meta-data stm can utilize. stm offers built-methods support (see specifically textProcessor() prepDocuments() methods (Roberts, Stewart, Tingley 2019)). use instead quanteda package (Benoit et al. 2018) provides broad range methods text pre-processing analysis, creating formats also supported stm.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"create-a-corpus","dir":"Articles","previous_headings":"Preparing and preprocessing the documents for text analysis","what":"Create a corpus","title":"Example: Topic modelling Covid preprints","text":"First, create corpus object dataframe preprints. corpus essentially library documents used next steps. specifies variable used uniquely identify documents variable holds textual content (preprint abstracts) processed. Echoing corpus provide basic information. variables original dataframe interpreted included document metadata (‘docvars’), later included STM topic modelling process.","code":"library(quanteda)  pubs_corpus <- covid_preprints %>%   quanteda::corpus(docid_field = \"doi\", text_field = \"abstract\")  # pubs_corpus # Corpus consisting of 29,692 documents and 6 docvars."},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"tokenize-and-preprocess","dir":"Articles","previous_headings":"Preparing and preprocessing the documents for text analysis","what":"Tokenize and preprocess","title":"Example: Topic modelling Covid preprints","text":"analysis corpus documents tokenized, .e. processing texts broken semantic units relevant analysis. common approach interpret word (typically designated whitespaces punctuation) token. applied well. quanteda offers several alternative approaches. Instead individual words, sequences words (n-grams) example used. tokenization method also provides several options preprocessing filtering tokens. example, tokenizing, simultaneously remove punctuation, numbers, special symbols URLs. Furthermore, split words containing hyphens, word like social-ecological thus split two individual tokens (social ecological). text preprocessing choices strongly influence results text analysis thoroughly explained, carefully evaluated ideally based theory (see (Denny Spirling 2018)).","code":"pubs_tokens <- pubs_corpus %>%   quanteda::tokens(remove_punct = TRUE,                    remove_symbols = TRUE,                    remove_numbers = TRUE,                    remove_url = TRUE,                    remove_separators = TRUE,                    split_hyphens = TRUE)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"create-a-document-feature-matrix","dir":"Articles","previous_headings":"Preparing and preprocessing the documents for text analysis","what":"Create a Document-feature matrix","title":"Example: Topic modelling Covid preprints","text":"tokens object used create document-feature matrix. statistical analysis reduces tokens matrix documents (rows) unique terms (columns) counts number occurrences term document. quanteda captures features supports general options terms (see quanteda documentation details).","code":"pubs_dfm <- pubs_tokens %>%   quanteda::dfm()"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"filter-terms-and-documents","dir":"Articles","previous_headings":"Preparing and preprocessing the documents for text analysis","what":"Filter terms and documents","title":"Example: Topic modelling Covid preprints","text":"followed (optional) processing filtering steps. common option example — reduce size data assist interpretation — removal -called stopwords (e.g. “”, “”, “” etc). step omitted reducing words (terms) word stem. stemming algorithm (several available) reduces words word stem. terms “universal”, “university” “universe” example reduced word stem “univers”; example indicates approach may require careful consideration. Stemming advantage potentially reduce size matrix substantially. options may considered reduce noise /size matrix. following code removes example terms (features) consist one character, terms appear least two different documents, furthermore remove documents contain least 5 tokens. example drops one document reduces number retained features half.","code":"pubs_dfm <- pubs_dfm %>%   quanteda::dfm_remove(pattern = quanteda::stopwords(\"english\")) #%>%   #quanteda::dfm_wordstem() # echo the result > pubs_dfm  Document-feature matrix of: 29,692 documents, 82,472 features (99.87% sparse) and 6 docvars.                 features docs             nitric oxide synthesised three isoforms synthases viz nnos neurons enos   10.1101/038398      6     6           1     1        1         1   1    1       2    1   10.1101/058511      0     0           0     0        0         0   0    0       0    0   10.1101/292979      0     0           0     2        0         0   0    0       0    0   10.1101/402370      0     0           0     0        0         0   0    0       0    0   10.1101/420737      0     0           0     0        0         0   0    0       0    0   10.1101/596700      0     0           0     0        0         0   0    0       0    0 [ reached max_ndoc ... 29,686 more documents, reached max_nfeat ... 82,462 more features ] pubs_dfm <- pubs_dfm %>%   quanteda::dfm_remove(min_nchar = 2) %>%   quanteda::dfm_trim(min_docfreq = 2, docfreq_type = \"count\") %>%   quanteda::dfm_subset(quanteda::ntoken(.) > 4) # echo the result > pubs_dfm  Document-feature matrix of: 29,691 documents, 37,093 features (99.72% sparse) and 6 docvars.                 features docs             nitric oxide synthesised three isoforms synthases viz neurons enos endothelial   10.1101/038398      6     6           1     1        1         1   1       2    1           2   10.1101/058511      0     0           0     0        0         0   0       0    0           0   10.1101/292979      0     0           0     2        0         0   0       0    0           0   10.1101/402370      0     0           0     0        0         0   0       0    0           0   10.1101/420737      0     0           0     0        0         0   0       0    0           0   10.1101/596700      0     0           0     0        0         0   0       0    0           0 [ reached max_ndoc ... 29,685 more documents, reached max_nfeat ... 37,083 more features ]"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"fitting-the-stm-topic-model","dir":"Articles","previous_headings":"Topic modeling","what":"Fitting the STM topic model","title":"Example: Topic modelling Covid preprints","text":"key input topic modelling algorithm number topics (K) model fit , set 20 (see separate document discussion suitable choices number topics). fitting topic model convert document-feature matrix native STM format. order fit topic model stm() function need set documents, vocabulary documents composed dataframe specifying values document meta-data variables (data) can used process “covariates” might influence prevalence topics document. example , ask stm incorporate origin document (server) publication year fitting topic model. argument prevalence = ~ server * s(year) expresses assume prevalence topics document influenced two variables, also interact, .e. work hypothesis different temporal trends expected documents published either two preprint servers1. consideration covariates optional. omitted model reduces Correlated Topic Model (Blei Lafferty 2007; Roberts, Stewart, Tingley 2019). also supply seed, allows replicate results topic modeling.","code":"library(stm)  covid_stm_docs <- quanteda::convert(pubs_dfm, to = \"stm\")  covid_model_K20 <- stm(documents = covid_stm_docs$documents,                        vocab = covid_stm_docs$vocab,                        data = covid_stm_docs$meta,                        prevalence = ~ server * s(year),                        K = 20,                        verbose = TRUE,                        seed = 9868467)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"estimating-the-effect-of-document-covariates","dir":"Articles","previous_headings":"Topic modeling","what":"Estimating the effect of document covariates","title":"Example: Topic modelling Covid preprints","text":"model converged can estimate effect document covariates topic prevalence. estimateEffect() function allows run regressions based formula specified first argument. identical formula used fitting topic model, regressions run 20 topics. metadata used previously needs supplied function addition topic model object. concludes fitting model. following sections step sample exploration topic model.","code":"covid_effect_K20 <- estimateEffect(1:20 ~ server * s(year),                                    stmobj = covid_model_K20,                                    metadata = covid_stm_docs$meta)"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"basic-topic-model-information","dir":"Articles","previous_headings":"Analysing and interpreting the topic model","what":"Basic topic model information","title":"Example: Topic modelling Covid preprints","text":"topic model defined two matrices capture probability distributions topics documents (gamma matrix) words (terms) topics (beta matrix). can start exploring built-functions stm. plot() function plots chart showing topic proportions topics model. topic identified unique ID (1-20) plot five words (terms) highest probability associated given topic. gives early indication distinct latent topics analysed subset preprints.  summary() function provides detailed view topics can help begin interpreting labeling 20 topics. Specifically, output shows four different sets words associated topic. ‘Highest Prob’ lists words highest probability associated topic. comparison different topics highlights term covid high probability several topics. list ‘FREX’ words summarizes words frequent exclusive topic, .e. characterize topic comparison topics (consult stm::labelTopics() details well Lift Score word sets).","code":"plot(covid_model_K20, n = 5) summary(covid_model_K20) ># A topic model with 20 topics, 29691 documents and a 37093 word dictionary. ># Topic 1 Top Words: >#       Highest Prob: model, can, covid, transmission, epidemic, data, disease  >#       FREX: npis, mathematical, compartmental, scenarios, seir, reproduction, sir  >#       Lift: 1we, abms, ao_scplowbstractc_scplowas, apt, artefact, asilv, asymptotically  >#       Score: distancing, social, epidemic, reproduction, npis, model, r0  ># Topic 2 Top Words: >#       Highest Prob: cov, sars, drug, antiviral, activity, drugs, covid  >#       FREX: src, figdir, o_linksmallfig, c_fig, m_fig, o_fig, gif  >#       Lift: k777, gif, pmmov, wwtps, 13k, 17k, 18k  >#       Score: mpro, antiviral, drug, inhibitors, protease, drugs, compounds  ># Topic 3 Top Words: >#       Highest Prob: covid, risk, age, mortality, ci, associated, years  >#       FREX: hispanic, ethnicity, pregnant, racial, black, smoking, preterm  >#       Lift: 65s, asmr, assault, backgroundethnic, backgroundracial, backgroundsocio, brunt  >#       Score: ci, age, women, mortality, ethnicity, aor, hispanic  ># Topic 4 Top Words: >#       Highest Prob: covid, health, pandemic, mental, social, study, survey  >#       FREX: loneliness, emotional, attitude, depression, insecurity, mental, anxiety  >#       Lift: insecurity, accelerometers, amhara, angry, anovas, asd, asleep  >#       Score: mental, anxiety, depression, respondents, social, psychological, students  ># Topic 5 Top Words: >#       Highest Prob: sars, cov, infection, testing, transmission, cases, children  >#       FREX: ifr, seroprevalence, schools, school, contacts, household, attack  >#       Lift: inmates, 19y, 35y, 39y, 9a, abidjan, addscovid  >#       Score: school, seroprevalence, children, schools, household, transmission, testing  ># Topic 6 Top Words: >#       Highest Prob: cov, sars, virus, viral, coronavirus, respiratory, infection  >#       FREX: bats, cats, deer, animals, covs, wildlife, hcov  >#       Lift: cats, 5x106, aav6, aegyptiacus, aethiops, affinis, agm  >#       Score: cov, sars, mice, rna, viruses, coronaviruses, animals  ># Topic 7 Top Words: >#       Highest Prob: patients, covid, hospital, disease, clinical, severe, admission  >#       FREX: acei, admission, arbs, admitted, icu, aki, aceis  >#       Lift: 1.1x109, 2020r1g1a1a01006229, 2l, 4.0x109, 40y, ahmad, ahrq  >#       Score: patients, admission, icu, hospital, admitted, ci, hospitalized  ># Topic 8 Top Words: >#       Highest Prob: covid, cases, countries, number, deaths, data, pandemic  >#       FREX: cfr, italy, cities, country, countries, fatality, china  >#       Lift: 1000m, 1th, 55th, abysmally, abyss, adhanom, adminstat  >#       Score: countries, cases, lockdown, deaths, country, cfr, daily  ># Topic 9 Top Words: >#       Highest Prob: protein, binding, spike, sars, cov, ace2, rbd  >#       FREX: conformational, cryo, conformation, glycans, conformations, nanobodies, residues  >#       Lift: 13c, 6lzg, 6m0j, 6vw1, 6vxx, aabpu, abdab  >#       Score: binding, rbd, protein, spike, ace2, proteins, epitopes  ># Topic 10 Top Words: >#       Highest Prob: data, can, learning, covid, using, model, based  >#       FREX: aerosol, n95, aerosols, respirators, decontamination, airborne, machine  >#       Lift: elastomeric, forehead, papr, radiomics, exhaled, singing, 0.3m  >#       Score: learning, masks, aerosol, machine, respirators, n95, mask  ># Topic 11 Top Words: >#       Highest Prob: vaccine, vaccination, covid, middle, vaccines, dot, dose  >#       FREX: hesitancy, dot, vaccinate, middle, hesitant, rollout, ve  >#       Lift: #949850, acceptant, adjrr, aesis, amparo, analysesthe, andersen  >#       Score: vaccination, vaccine, dot, booster, dose, vaccinated, middle  ># Topic 12 Top Words: >#       Highest Prob: studies, care, covid, health, research, data, pandemic  >#       FREX: reviews, telemedicine, preprints, scoping, articles, blacksquare, publications  >#       Lift: preprints, 1.2m, aas, abbreviating, accustomed, activists, advisor  >#       Score: review, care, services, articles, reviews, pubmed, service  ># Topic 13 Top Words: >#       Highest Prob: sars, cov, genome, mutations, sequencing, viral, variants  >#       FREX: phylogenetic, gisaid, clades, wgs, genomes, genomic, haplotype  >#       Lift: clades, snvs, 1.1.7s, 11083g, 14408c, 17del, 20a  >#       Score: mutations, genome, wastewater, genomes, sequences, sequencing, genomic  ># Topic 14 Top Words: >#       Highest Prob: cells, cell, sars, cov, expression, infection, ace2  >#       FREX: autophagy, mirnas, mirna, at2, ifns, ciliated, scrna  >#       Lift: 25hc, angiotensinogen, antagonizes, apcs, arf6, asgr1, at2s  >#       Score: cells, expression, ace2, cell, genes, epithelial, tmprss2  ># Topic 15 Top Words: >#       Highest Prob: antibody, sars, cov, antibodies, igg, responses, vaccine  >#       FREX: iga, bau, igg, humoral, immunogenicity, as03, reactogenicity  >#       Lift: 1x1011, 28d, 30ug, ad26cov2, addas03, adhu5, atellica  >#       Score: igg, antibody, antibodies, neutralizing, rbd, vaccine, spike  ># Topic 16 Top Words: >#       Highest Prob: sars, cov, pcr, samples, rt, test, testing  >#       FREX: ag, rdt, rdts, lod, rt, panbio, kits  >#       Lift: poct, cobas, panbio, #yomecorono, 1.6x104, 10min, 15min  >#       Score: rt, pcr, assay, samples, saliva, detection, assays  ># Topic 17 Top Words: >#       Highest Prob: variants, omicron, variant, delta, ba, cov, sars  >#       FREX: omicron, ba, xbb, subvariants, delta, bq, voc  >#       Lift: 1.5s, 129s2, 1f11, 2.86s, 3b8, 417n, 75d30121c11061  >#       Score: omicron, ba, variants, variant, delta, mutations, voc  ># Topic 18 Top Words: >#       Highest Prob: covid, patients, disease, severe, immune, inflammatory, associated  >#       FREX: autoantibodies, ipf, balf, neutrophils, il, fibrosis, autoantibody  >#       Lift: 18f, 24hr, a2ar, aab, actinobacteria, activin, adiponectin  >#       Score: inflammatory, il, patients, cytokine, inflammation, cytokines, endothelial  ># Topic 19 Top Words: >#       Highest Prob: patients, treatment, covid, group, days, day, trial  >#       FREX: placebo, randomized, hcq, soc, azithromycin, arm, tocilizumab  >#       Lift: 200mg, 400mg, 500mg, 600mg, 800mg, aureobasidium, ayush  >#       Score: placebo, hcq, trial, patients, randomized, tocilizumab, hydroxychloroquine  ># Topic 20 Top Words: >#       Highest Prob: covid, symptoms, long, workers, infection, participants, study  >#       FREX: hcws, taste, smell, hcw, fatigue, workers, headache  >#       Lift: chemesthetic, dirty, eyewear, firefighters, ohs, principality, psychophysical  >#       Score: symptoms, hcws, workers, participants, symptom, hcw, fatigue"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"topic-document-and-term-topic-distributions","dir":"Articles","previous_headings":"Analysing and interpreting the topic model","what":"Topic-document and term-topic distributions","title":"Example: Topic modelling Covid preprints","text":"mentioned, topic model defined gamma (distribution topics words) beta (distribution terms topics) matrices. help tidytext package can extract dataframes detailed analysis. row following dataframe lists probability (gamma) given topic occurring given document2. Similarly, beta matrix (extracted dataframe) lists row probability (beta) given term occurring given topic. Starting beta matrix can create word clouds explore useful semantic labels topic.","code":"># Rows: 593,820 ># Columns: 3 ># $ document  [3m [38;5;246m<int> [39m [23m 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18… ># $ topic     [3m [38;5;246m<int> [39m [23m 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ># $ gamma     [3m [38;5;246m<dbl> [39m [23m 0.001283143, 0.003547179, 0.003745510, 0.005495076, 0.0630417… ># Rows: 741,860 ># Columns: 3 ># $ topic  [3m [38;5;246m<int> [39m [23m 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1… ># $ term   [3m [38;5;246m<chr> [39m [23m \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\"… ># $ beta   [3m [38;5;246m<dbl> [39m [23m 1.874650e-112, 2.519509e-119, 1.248970e-118, 6.665355e-160, 3.21…"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"understanding-and-labeling-topics","dir":"Articles","previous_headings":"Analysing and interpreting the topic model","what":"Understanding and labeling topics","title":"Example: Topic modelling Covid preprints","text":"mentioned previously stm can use word probabilities also compute FREX (frequent exclusive) words per topic. can retrieved stm::labelTopics() function, returns ordered lists different word sets characterizing topic. can combine information high probability FREX words create word clouds topic, might help assign summary label topic. Word clouds showing 50 probable terms per topic. Words scaled normalized probability per topic, terms also among top 20 FREX terms highlighted orange. readability, terms ‘sars’, ‘cov’ ‘covid’ removed occur high probability topics. review combination FREX high probability terms distinct topics emerging, : “epidemic models” (Topic 1), “vaccines” (Topic 11), “testing” (Topic 16), “virus variants” (Topic 17), “treatments” (Topic 2), “mortality risks” (Topic 3), “mental health” (Topic 4), “country-wise case reports” (Topic 8), “virus molecular structure” (Topic 9). Deriving semantic labels also benefit review sample documents representative certain topics, .e. topic model assigns high topic proportion given topic document. Furthermore, consistency assigned semantic labels checked prior analysis (see example oolong package systematic approach).","code":"library(tidyr) library(tibble)  # get the top FREX words frex_top20 <- as.data.frame(labelTopics(covid_model_K20, n = 20)$frex) %>%   rownames_to_column(var = \"topic\") %>%   pivot_longer(starts_with(\"V\"), values_to = \"term\") %>%   mutate(is_frex = 1) %>%   select(-name)  topic_words <- tidytext::tidy(covid_model_K20, matrix = \"beta\") %>%   #filter(!(term %in% c(\"sars\", \"cov\", \"covid\"))) %>%    mutate(topic = as.character(topic)) %>%   group_by(topic) %>%   arrange(-beta) %>%   slice_head(n = 50) %>%   mutate(beta_norm = (beta - min(beta)) / (max(beta) - min(beta))) %>%   ungroup() %>%   left_join(frex_top20, by = c(\"topic\", \"term\")) %>%   mutate(is_frex = ifelse(is.na(is_frex), \"0\", \"1\")) %>%   filter(!(term %in% c(\"sars\", \"cov\", \"covid\"))) %>%   mutate(topic = paste(\"Topic\", topic))  ggplot(topic_words, aes(label = term, size = beta_norm, color = is_frex)) +   ggwordcloud::geom_text_wordcloud_area(shape = \"square\",                                         family = \"Arial\",                                         rm_outside = TRUE) +   scale_radius(range = c(4, 15)) +   scale_color_manual(values = c(\"0\" = \"black\", \"1\" = \"#D55E00\")) +    facet_wrap(~topic, ncol = 4)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"covariate-effects","dir":"Articles","previous_headings":"Analysing and interpreting the topic model","what":"Covariate effects","title":"Example: Topic modelling Covid preprints","text":"key feature STM incorporation document covariates topic model. example considered publication year preprint server covariates might influence prevalence topic document. also applied regression covariates fit model, extracted stm::estimateEffect(). first exploration can print regression tables selected topics. following sections illustrate exploration covariate effects several examples.","code":"summary(covid_effect_K20) >#  ># Call: ># estimateEffect(formula = 1:20 ~ server * s(year), stmobj = covid_model_K20,  >#     metadata = covid_stm_docs$meta) >#  >#  ># Topic 1: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.0234719  0.0037166   6.315 2.73e-10 *** ># servermedrxiv           0.1239381  0.0043477  28.507  < 2e-16 *** ># s(year)1               -0.0022752  0.0147584  -0.154    0.877     ># s(year)2               -0.0003647  0.0154166  -0.024    0.981     ># s(year)3                0.0082955  0.0067326   1.232    0.218     ># servermedrxiv:s(year)1 -0.0691671  0.0173325  -3.991 6.61e-05 *** ># servermedrxiv:s(year)2 -0.0968968  0.0191428  -5.062 4.18e-07 *** ># servermedrxiv:s(year)3 -0.0705290  0.0084830  -8.314  < 2e-16 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 2: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.098658   0.002891  34.128  < 2e-16 *** ># servermedrxiv          -0.085945   0.003160 -27.196  < 2e-16 *** ># s(year)1               -0.019987   0.011326  -1.765   0.0776 .   ># s(year)2               -0.011235   0.013453  -0.835   0.4036     ># s(year)3               -0.028620   0.004595  -6.228 4.77e-10 *** ># servermedrxiv:s(year)1  0.021613   0.012586   1.717   0.0860 .   ># servermedrxiv:s(year)2  0.008234   0.014412   0.571   0.5678     ># servermedrxiv:s(year)3  0.030409   0.005326   5.710 1.14e-08 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 3: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.011093   0.002806   3.953 7.74e-05 *** ># servermedrxiv           0.053926   0.003296  16.362  < 2e-16 *** ># s(year)1               -0.002506   0.011290  -0.222    0.824     ># s(year)2               -0.002072   0.011794  -0.176    0.861     ># s(year)3                0.001220   0.004882   0.250    0.803     ># servermedrxiv:s(year)1  0.014935   0.013706   1.090    0.276     ># servermedrxiv:s(year)2  0.014325   0.014927   0.960    0.337     ># servermedrxiv:s(year)3  0.029830   0.006526   4.571 4.88e-06 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 4: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.008914   0.003293   2.707  0.00679 **  ># servermedrxiv           0.057676   0.003871  14.899  < 2e-16 *** ># s(year)1                0.004607   0.013407   0.344  0.73113     ># s(year)2               -0.005204   0.013796  -0.377  0.70600     ># s(year)3                0.004447   0.005871   0.758  0.44873     ># servermedrxiv:s(year)1  0.020370   0.016462   1.237  0.21595     ># servermedrxiv:s(year)2 -0.003930   0.017894  -0.220  0.82617     ># servermedrxiv:s(year)3  0.020345   0.007764   2.620  0.00879 **  ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 5: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             4.960e-03  2.361e-03   2.101   0.0356 *   ># servermedrxiv           5.425e-02  2.801e-03  19.366   <2e-16 *** ># s(year)1               -8.239e-04  9.458e-03  -0.087   0.9306     ># s(year)2                7.381e-05  9.913e-03   0.007   0.9941     ># s(year)3                1.060e-03  4.166e-03   0.254   0.7992     ># servermedrxiv:s(year)1  2.613e-02  1.158e-02   2.256   0.0241 *   ># servermedrxiv:s(year)2 -1.667e-03  1.216e-02  -0.137   0.8910     ># servermedrxiv:s(year)3 -8.480e-03  5.381e-03  -1.576   0.1150     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 6: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.148609   0.003827  38.830  < 2e-16 *** ># servermedrxiv          -0.115780   0.004182 -27.683  < 2e-16 *** ># s(year)1               -0.021079   0.013439  -1.569   0.1168     ># s(year)2               -0.049226   0.012082  -4.074 4.63e-05 *** ># s(year)3               -0.043796   0.006027  -7.266 3.78e-13 *** ># servermedrxiv:s(year)1  0.005797   0.014923   0.388   0.6977     ># servermedrxiv:s(year)2  0.035470   0.013870   2.557   0.0106 *   ># servermedrxiv:s(year)3  0.031055   0.006928   4.482 7.41e-06 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 7: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.010638   0.002948   3.608 0.000309 *** ># servermedrxiv           0.086116   0.003501  24.595  < 2e-16 *** ># s(year)1               -0.004010   0.011740  -0.342 0.732686     ># s(year)2               -0.007740   0.012402  -0.624 0.532569     ># s(year)3               -0.003281   0.005155  -0.636 0.524541     ># servermedrxiv:s(year)1 -0.049330   0.014762  -3.342 0.000834 *** ># servermedrxiv:s(year)2 -0.019767   0.015955  -1.239 0.215378     ># servermedrxiv:s(year)3 -0.038540   0.006526  -5.906 3.55e-09 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 8: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.027287   0.003034   8.994  < 2e-16 *** ># servermedrxiv           0.108650   0.003572  30.415  < 2e-16 *** ># s(year)1               -0.012962   0.012383  -1.047  0.29522     ># s(year)2               -0.018376   0.012456  -1.475  0.14015     ># s(year)3               -0.017099   0.005203  -3.287  0.00102 **  ># servermedrxiv:s(year)1 -0.088312   0.014795  -5.969 2.41e-09 *** ># servermedrxiv:s(year)2 -0.046526   0.015270  -3.047  0.00231 **  ># servermedrxiv:s(year)3 -0.060195   0.006494  -9.270  < 2e-16 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 9: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.170514   0.004557  37.418  < 2e-16 *** ># servermedrxiv          -0.163993   0.004776 -34.340  < 2e-16 *** ># s(year)1                0.017997   0.019100   0.942   0.3461     ># s(year)2               -0.034745   0.020130  -1.726   0.0844 .   ># s(year)3               -0.027992   0.006508  -4.301 1.70e-05 *** ># servermedrxiv:s(year)1 -0.010881   0.020203  -0.539   0.5902     ># servermedrxiv:s(year)2  0.033180   0.021912   1.514   0.1300     ># servermedrxiv:s(year)3  0.027906   0.007096   3.932 8.43e-05 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 10: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.0447093  0.0033275  13.437  < 2e-16 *** ># servermedrxiv           0.0117892  0.0036085   3.267  0.00109 **  ># s(year)1                0.0042065  0.0145117   0.290  0.77192     ># s(year)2                0.0002803  0.0130954   0.021  0.98292     ># s(year)3                0.0261672  0.0058179   4.498 6.89e-06 *** ># servermedrxiv:s(year)1 -0.0177231  0.0161711  -1.096  0.27310     ># servermedrxiv:s(year)2 -0.0305140  0.0151908  -2.009  0.04458 *   ># servermedrxiv:s(year)3 -0.0409332  0.0069885  -5.857 4.76e-09 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 11: >#  ># Coefficients: >#                        Estimate Std. Error t value Pr(>|t|)     ># (Intercept)            0.005076   0.002329   2.180  0.02928 *   ># servermedrxiv          0.008193   0.002685   3.051  0.00228 **  ># s(year)1               0.009869   0.009926   0.994  0.32007     ># s(year)2               0.010167   0.010189   0.998  0.31836     ># s(year)3               0.006416   0.004248   1.511  0.13091     ># servermedrxiv:s(year)1 0.057244   0.011704   4.891 1.01e-06 *** ># servermedrxiv:s(year)2 0.073526   0.012475   5.894 3.81e-09 *** ># servermedrxiv:s(year)3 0.047038   0.005914   7.954 1.87e-15 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 12: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.022005   0.002842   7.742 1.01e-14 *** ># servermedrxiv           0.041928   0.003402  12.325  < 2e-16 *** ># s(year)1               -0.008509   0.011263  -0.756    0.450     ># s(year)2               -0.005858   0.012243  -0.479    0.632     ># s(year)3               -0.002646   0.004882  -0.542    0.588     ># servermedrxiv:s(year)1 -0.006689   0.013816  -0.484    0.628     ># servermedrxiv:s(year)2  0.009547   0.015679   0.609    0.543     ># servermedrxiv:s(year)3  0.034847   0.006434   5.416 6.15e-08 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 13: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.104392   0.003136  33.291  < 2e-16 *** ># servermedrxiv          -0.086376   0.003435 -25.144  < 2e-16 *** ># s(year)1               -0.031695   0.015408  -2.057   0.0397 *   ># s(year)2               -0.027882   0.015087  -1.848   0.0646 .   ># s(year)3               -0.023379   0.005609  -4.168 3.08e-05 *** ># servermedrxiv:s(year)1  0.078014   0.017859   4.368 1.26e-05 *** ># servermedrxiv:s(year)2  0.028083   0.016916   1.660   0.0969 .   ># servermedrxiv:s(year)3  0.041212   0.006676   6.173 6.79e-10 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 14: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.124587   0.003420  36.433   <2e-16 *** ># servermedrxiv          -0.112707   0.003638 -30.979   <2e-16 *** ># s(year)1                0.004331   0.015037   0.288    0.773     ># s(year)2               -0.007535   0.015734  -0.479    0.632     ># s(year)3                0.007555   0.006294   1.200    0.230     ># servermedrxiv:s(year)1 -0.003295   0.015962  -0.206    0.836     ># servermedrxiv:s(year)2  0.005338   0.016746   0.319    0.750     ># servermedrxiv:s(year)3 -0.005154   0.007122  -0.724    0.469     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 15: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.053504   0.003540  15.116  < 2e-16 *** ># servermedrxiv          -0.027440   0.003984  -6.887 5.81e-12 *** ># s(year)1                0.044569   0.014918   2.988  0.00281 **  ># s(year)2                0.024810   0.015585   1.592  0.11140     ># s(year)3                0.017771   0.006496   2.736  0.00622 **  ># servermedrxiv:s(year)1  0.003799   0.017396   0.218  0.82715     ># servermedrxiv:s(year)2  0.033589   0.017700   1.898  0.05775 .   ># servermedrxiv:s(year)3 -0.003423   0.007622  -0.449  0.65339     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 16: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.0531715  0.0034654  15.344  < 2e-16 *** ># servermedrxiv           0.0176033  0.0040362   4.361 1.30e-05 *** ># s(year)1               -0.0495250  0.0128687  -3.848 0.000119 *** ># s(year)2               -0.0294419  0.0131198  -2.244 0.024834 *   ># s(year)3               -0.0279160  0.0057295  -4.872 1.11e-06 *** ># servermedrxiv:s(year)1  0.0609005  0.0149578   4.071 4.68e-05 *** ># servermedrxiv:s(year)2  0.0012147  0.0160254   0.076 0.939581     ># servermedrxiv:s(year)3 -0.0007564  0.0072205  -0.105 0.916574     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 17: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.012496   0.002366   5.282 1.29e-07 *** ># servermedrxiv          -0.010830   0.002659  -4.073 4.65e-05 *** ># s(year)1                0.062486   0.011957   5.226 1.74e-07 *** ># s(year)2                0.167257   0.016095  10.392  < 2e-16 *** ># s(year)3                0.074795   0.005273  14.184  < 2e-16 *** ># servermedrxiv:s(year)1 -0.043754   0.013177  -3.320    9e-04 *** ># servermedrxiv:s(year)2 -0.079944   0.017963  -4.450 8.60e-06 *** ># servermedrxiv:s(year)3 -0.037963   0.006066  -6.258 3.96e-10 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 18: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.055611   0.003061  18.168  < 2e-16 *** ># servermedrxiv          -0.019843   0.003478  -5.706 1.17e-08 *** ># s(year)1                0.005720   0.012139   0.471  0.63752     ># s(year)2                0.004216   0.012671   0.333  0.73936     ># s(year)3                0.029496   0.005780   5.103 3.37e-07 *** ># servermedrxiv:s(year)1 -0.004567   0.014656  -0.312  0.75536     ># servermedrxiv:s(year)2 -0.004789   0.015299  -0.313  0.75429     ># servermedrxiv:s(year)3 -0.020749   0.006881  -3.016  0.00257 **  ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 19: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.013572   0.002578   5.264 1.42e-07 *** ># servermedrxiv           0.027342   0.003001   9.111  < 2e-16 *** ># s(year)1                0.000346   0.009880   0.035   0.9721     ># s(year)2               -0.006231   0.010499  -0.593   0.5529     ># s(year)3               -0.003132   0.004406  -0.711   0.4771     ># servermedrxiv:s(year)1 -0.002951   0.012138  -0.243   0.8079     ># servermedrxiv:s(year)2  0.028101   0.013185   2.131   0.0331 *   ># servermedrxiv:s(year)3  0.002783   0.005749   0.484   0.6283     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 20: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             6.721e-03  1.932e-03   3.478 0.000506 *** ># servermedrxiv           3.143e-02  2.206e-03  14.251  < 2e-16 *** ># s(year)1               -1.592e-03  7.672e-03  -0.208 0.835604     ># s(year)2                3.583e-05  8.156e-03   0.004 0.996495     ># s(year)3                5.082e-04  3.341e-03   0.152 0.879090     ># servermedrxiv:s(year)1  8.835e-03  9.661e-03   0.914 0.360490     ># servermedrxiv:s(year)2  1.277e-02  1.069e-02   1.194 0.232447     ># servermedrxiv:s(year)3  2.132e-02  4.567e-03   4.669 3.05e-06 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"publication-year","dir":"Articles","previous_headings":"Analysing and interpreting the topic model > Covariate effects","what":"Publication year","title":"Example: Topic modelling Covid preprints","text":"stm offers several built-methods explore covariate effects visually. visualization effect preprint publication year expected topic proportions confirm trends appear match intuitively different phases Covid-19 pandemic. Modelling spread infections (Topic 1) high relevance initially, declined later, applies (PCR-)testing (Topic 16), vaccines (Topic 11) received limited coverage earlier preprints, became important later years developed distributed.  Alternatively, stminsights package used extract regression information stm effects object create customized charts.","code":"plot(covid_effect_K20,      covariate = \"year\",      method = \"continuous\",      model = covid_model_K20,      topics = c(1, 16, 11),      xaxt = \"n\",      main = 'Effect of publication year on prevalence of Topic 1 (\"epidemic \\nmodels\"), Topic 16 (\"testing\") and Topic 11 (\"vaccines\")',      labeltype = \"prob\",      xlab = \"Publication year\") axis(1, at = c(\"2020\",\"2021\",\"2022\",\"2023\"), labels = c(2020, 2021, 2022, 2023)) library(stminsights)  year_effect <- get_effects(estimates = covid_effect_K20,                             variable = \"year\",                            type = \"continuous\")  year_effect %>%   mutate(topic = as.character(topic)) %>%   mutate(topic = paste(\"Topic\", topic)) %>%     ggplot(aes(x = value, y = proportion)) +       geom_line() +       geom_ribbon(aes(ymin = lower, ymax = upper),                    alpha = 0.2, linetype = 0)  +       xlab(\"Publication year\") +       ylab(\"Topic prevalence\") +       facet_wrap(~topic, ncol = 4) +       theme_minimal()"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"preprint-server","dir":"Articles","previous_headings":"Analysing and interpreting the topic model > Covariate effects","what":"Preprint server","title":"Example: Topic modelling Covid preprints","text":"model also incorporated preprint server (bioRxiv medRxiv) covariate. hypothesized prevalence certain topics influenced covariate, .e. likely see certain topics either bioRxiv medRxiv. STM interprets treatment (see (Roberts et al. 2014) background examples) can extract effect treatment regression object returned estimateEffect(). stm::plot() offers different methods explore effects. figure lists effect ‘treatment medrxiv’ topics model. treatment can positive negative effect. can example see Topic 4 (“mental health”) can expected higher prevalence medRxiv preprints, whereas Topic 9 (“virus molecular structure”) much lower prevalence medRxiv preprints, .e. expected higher prevalence bioRxiv preprints.  can also compare topical prevalence effect covariate values single topic. figure confirms previous observation Topic 9 (“virus molecular structure”) prevalence close zero medRxiv preprints prevalence approximately 0.17 bioRxiv preprints, .e. seems appear almost exclusively latter.","code":"plot(covid_effect_K20,       covariate = \"server\",      #topics = c(9, 10, 16, 1),      model = covid_model_K20,       method = \"difference\",      cov.value1 = \"medrxiv\", cov.value2 = \"biorxiv\",      xlab = \"higher biorxiv prevalence ... higher medrxiv prevalence\",      xlim = c(-0.19, 0.1),      #labeltype = \"prob\",      main = \"Effect of preprint server ('treatment medrxiv')\") plot(covid_effect_K20,       covariate = \"server\",      topics = c(9),      model = covid_model_K20,        method = \"pointestimate\",      xlab = \"Topical prevalence\",      xlim = c(-0.04, 0.2),      #labeltype = \"prob\",      main = \"Effect of preprint server covariate for Topic 9\")"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"combination-of-preprint-server-and-publication-year","dir":"Articles","previous_headings":"Analysing and interpreting the topic model > Covariate effects","what":"Combination of preprint server and publication year","title":"Example: Topic modelling Covid preprints","text":"Finally, can also explore combined effect covariates; assumed interacting effect two covariates server year. plot visualizes Topic 17 (“virus variants”) illustrates topical prevalence increased throughout pandemic preprints topic apparently received coverage bioRxiv preprints.  , stminsights can used retrieve information create customized visualizations combined covariate effect.","code":"biorxiv_effect <- get_effects(covid_effect_K20,                               variable = \"year\", type = \"continuous\",                                moderator = \"server\", modval = \"biorxiv\")  medrxiv_effect <- get_effects(covid_effect_K20,                               variable = \"year\", type = \"continuous\",                                moderator = \"server\", modval = \"medrxiv\")  server_effects <- bind_rows(biorxiv_effect, medrxiv_effect)  server_effects %>%   mutate(topic = as.character(topic)) %>%   mutate(topic = paste(\"Topic\", topic)) %>%     ggplot(aes(x = value, y = proportion, color = moderator,                group = moderator, fill = moderator)) +       geom_line() +       geom_ribbon(aes(ymin = lower, ymax = upper,                        fill = moderator), alpha = 0.2, linetype = 0) +       xlab(\"Publication year\") +       ylab(\"Topic prevalence\") +       facet_wrap(~topic, ncol = 4) +       theme_minimal() +       theme(legend.position = \"bottom\")"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"topic-correlations","dir":"Articles","previous_headings":"Analysing and interpreting the topic model > Exploring the topic structure","what":"Topic correlations","title":"Example: Topic modelling Covid preprints","text":"Finally, considering STM extending (Roberts, Stewart, Tingley 2019) correlated topic model (Blei Lafferty 2007) may also explore topics frequently cooccuring. topic correlation matrix retrieved stm::topicCorr() can plotted. resulting figure indicates least two clusters topics.  correlation matrix can used analysis (e.g. networks clusters) alternative visualizations. outside scope example course module. illustration, following figure creates alternative network visualization, nodes colored according community analysis topical network, reveals four distinct topical clusters.","code":"covid_topic_correlations <- topicCorr(covid_model_K20)  plot(covid_topic_correlations)"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/evaluate-k.html","id":"k-the-number-of-topics","dir":"Articles","previous_headings":"","what":"‘K’ — the number of topics","title":"Choosing the number of topics (K)","text":"Topic modeling algorithms like stm() unsupervised classification methods, require one input parameter, K, number topics fit given document collection. Choosing suitable number topics one key challenges fitting topic model. fact correct best number topics given document corpus. Ultimately, chosen number topics defines level granularity can explore topical structure document collection. One factor choice K thus practical considerations questions topic model help answer. exist however number metrics assess well given number topics can explain document collection (Roberts, Stewart, Tingley 2019; Wallach et al. 2009). stm() package supports several approaches. sample analysis included vignette(\"covid-preprint-topics\") considered measures determine suitable K, one ideally producing good model fit deliver navigable number topics exploratory analysis. stm package offers two approaches determine suitable K, either letting stm decide number topics fitting multiple models different topic numbers parallel comparing various measures goodness model fit. approaches discussed . Note pre-processing options available preparing document corpus topic modeling impact runtime duration algorithm may also impact model fit (see vignette(\"covid-preprint-topics\") explanation different steps).","code":""},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/evaluate-k.html","id":"let-stm-determine-a-suitable-topic-number","dir":"Articles","previous_headings":"Finding the best ‘K’","what":"Let stm determine a suitable topic number","title":"Choosing the number of topics (K)","text":"main stm function offers option set K 0 triggers processing workflow determines suitable number topics. option uses approach described (Mimno Lee 2014) (however deterministic). Since approach deterministic, different executions setting may result different topic numbers different word topic assignments.","code":"model_K0 <- stm(mydocs_dfm, K = 0)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/evaluate-k.html","id":"comparing-topic-models-with-different-ks","dir":"Articles","previous_headings":"Finding the best ‘K’","what":"Comparing topic models with different Ks","title":"Choosing the number of topics (K)","text":"detailed (resource-intensive approach) fit models multiple options K, evaluate best suitable choice based different measures goodness fit. following, use four metrics — held-likelihood (Wallach et al. 2009), residual dispersion (Taddy 2012), semantic coherence (Mimno et al. 2011) exclusivity (Roberts, Stewart, Tingley 2019) — assess quality topic models different Ks. stm package provides searchK()function, allows run multiple model fits different Ks returns different measures model fit. use instead alternative approach employing future furrr packages1. Held-likelihood, requires evaluation topic model unseen data set. follow default approach suggested (Roberts, Stewart, Tingley 2019) use stm’s make.heldout method split document corpus (transformed document-feature matrix) training testing set — models fit training set held-likelihood evaluated testing set. preparation evaluating models use stm’s make.heldout function, splits given document corpus two parts, core document set fitting model(s) “missing” set can used measure — function eval.heldout — well model performs unseen document set. Fo illustration two subsets bioRxiv medRxiv preprints potentially covering topic “biodiversity” “sustainability/social-ecological systems” respectively created. subsets, results fitting models K’s ranging 5 100 (intervals 5) evaluated. Depending system configuration, fitting models can take several hours. code section assume previously created document-feature matrix (pubs_dfm) document set. Now can explore results four metrics mentioned earlier.  document completion held-likelihood (Wallach et al. 2009) residual dispersion (Taddy 2012) help us assess well topic model explains given document corpus. Exclusivity (Roberts, Stewart, Tingley 2019)semantic coherence (Mimno et al. 2011) can help assess quality topic assignments interpretability. order compute held-likelihood created held-dataset. held-likelihood measures well topic model performs previously unseen documents. specific number identifies best K thus best topic model, held-likelihood allows comparisons different models, smaller numbers indicating better fit. evaluated biodiversity preprints subset held-likelihood peaks 15 topics declines quickly higher Ks, SES preprints peaks 40 topics show large differences evaluated Ks. residual dispersion can used measure unexplained variance topic model (Taddy 2012). measure can used compare different model options. evaluation indicates larger K’s seem reduce residual overdispersion, improvements level around 30 topics evaluated subsets increases higher Ks. Semantic coherence measures frequently probable words topic co-occur modeled documents. coherence metric appears align well expert evaluations topic quality (Mimno et al. 2011). (Roberts, Stewart, Tingley 2019) suggest however semantic coherence can easily achieved small number topics dominated common words. line evaluations document subsets showing average semantic coherence topics decreases larger Ks, slower however around 65 topics, intermediate peak 40 topics. (Roberts, Stewart, Tingley 2019) suggest additional measure: exclusivity. topic’s exclusivity score considers exclusivity frequency words topic (Roberts, Stewart, Tingley 2019; Bischof Airoldi 2012). Simply put, topic models higher exclusivity scores indicate better delineation topics. Large Ks lead higher mean exclusivity topics, example gains appear smaller around 20 topic. Deciding number topics based latter metrics thus trade-maximizing semantic coherence exclusivity. combined assessment four metrics suggest clear winner. SES preprints subset make case topic numbers range 20 50 topics. common approach arrive suitable choice K evaluate topic numbers iteratively, .e. example potentially helpful next evaluate Ks range 20 50. can therefore helpful look values exclusivity semantic coherence individual topics set models, approach also suggested (Roberts, Stewart, Tingley 2019). figure summarizes approach SES preprints subset, showing combination exclusivity semantic coherence topic topic models Ks ranging 15 55.  exploration level individual topics illustrates exclusivity improves expense semantic coherence. , identify ‘clear winner’, Ks range 30 45 might reasonable choices sample analysis — large gains topic exclusivity beyond 30 topics, topics show distinctly lower semantic coherence beyond 45 topics. Ultimately, approach can help identify suitable range Ks, choice also informed explored research questions, practical considerations ideally domain knowledge analysed documents.","code":"library(stm)  # a seed is needed for replicability  heldout_corpus <- make.heldout(mydocs_dfm, seed = 6406852) library(quanteda) library(stm) library(furrr) library(purrr)  # create a set of Ks to evaluate K_values <- tibble::tibble(K = seq.int(from = 5, to = 100, by = 5))  # create a heldout corpus for evaluation of model fit # (a seed can be provided for replicability) pubs_dfm_heldout <- make.heldout(pubs_dfm, seed = 1234567)  # create document format required by stm stm_docs <- quanteda::convert(pubs_dfm_heldout, to = \"stm\")  # consult the futures package for details on parallelization options plan(\"multisession\")  # fit the STM models with different Ks # supplying a seed allows replication, but can also be retrieved from the model models_K5_100 <- K_values %>%   mutate(topic_model = future_map(K, ~stm(documents = stm_docs$documents,                                           vocab = stm_docs$vocab,                                           data = stm_docs$meta,                                           prevalence = ~ server * s(year),                                           K = .,                                           verbose = FALSE,                                           seed = 8912388),                                   .options = furrr_options(seed = 8912388)))  # extract model fit metrics metrics_K5_100 <- models_K5_100 %>%   mutate(exclusivity = future_map(topic_model, exclusivity),          semantic_coherence = future_map(topic_model, semanticCoherence,                                          pubs_dfm_heldout$documents),          eval_heldout = future_map(topic_model, eval.heldout,                                    pubs_dfm_heldout$missing),          residual = future_map(topic_model, checkResiduals,                                pubs_dfm_heldout$documents))  plan(\"sequential\")"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/evaluate-k.html","id":"appendix","dir":"Articles","previous_headings":"","what":"Appendix","title":"Choosing the number of topics (K)","text":"following sections show additional evaluations (subsets ) bioRxiv/medRxiv preprints.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"getting-the-document-data","dir":"Articles","previous_headings":"Exercise tasks","what":"Getting the document data","title":"Exercise 1: Topic modeling biodiversity preprints","text":"assume created local copy preprint data run analysis (see information code samples “Getting document data” vignette(\"covid-preprint-topics\")).","code":"load(url(\"PREPRINT_RDATA_LOCATION_HERE\"))"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"cleaning-filtering-and-annotating-the-data","dir":"Articles","previous_headings":"Exercise tasks","what":"Cleaning, filtering and annotating the data","title":"Exercise 1: Topic modeling biodiversity preprints","text":"example planning explore whether publication status influences topic prevalence. therefore adapt time range consider preprints added 2017 2021. reduce subset preprints reference term ‘biodiversity’ either preprint title abstract.","code":"# adapt based on the covid preprints example"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"create-a-corpus","dir":"Articles","previous_headings":"Exercise tasks > Preparing and preprocessing the documents for text analysis","what":"Create a corpus","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Create corpus explore properties.","code":"# quanteda is used for corpus creation"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"tokenize-and-preprocess","dir":"Articles","previous_headings":"Exercise tasks > Preparing and preprocessing the documents for text analysis","what":"Tokenize and preprocess","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Tokenize applying steps Covid preprint example.","code":"# quanteda is used for tokenization"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"create-a-document-feature-matrix","dir":"Articles","previous_headings":"Exercise tasks > Preparing and preprocessing the documents for text analysis","what":"Create a Document-feature matrix","title":"Exercise 1: Topic modeling biodiversity preprints","text":"","code":"# quanteda is used for creation of a DFM"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"filter-terms-and-documents","dir":"Articles","previous_headings":"Exercise tasks > Preparing and preprocessing the documents for text analysis","what":"Filter terms and documents","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Remove stopwords document-feature-matrix. Explore properties. Filter tokens documents applying approach Covid preprint example.","code":"# quanteda is used for stopword removal # quanteda is used for filtering"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"fitting-the-stm-topic-model","dir":"Articles","previous_headings":"Exercise tasks > Topic modeling","what":"Fitting the STM topic model","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Fit stm topic model 10 topics prepared data. model consider interacting effect covariates is_published publication year topical prevalence. Apply seed argument value 9868467.","code":"# convert the DFM into stm format and run the stm() function"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"estimating-the-effect-of-document-covariates","dir":"Articles","previous_headings":"Exercise tasks > Topic modeling","what":"Estimating the effect of document covariates","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Evaluate effect previously chosen topic prevalence covariates topics. concludes fitting model. following sections step sample exploration topic model.","code":"# estimateEffect() on the topic model"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"basic-topic-model-information","dir":"Articles","previous_headings":"Exercise tasks > Analysing and interpreting the topic model","what":"Basic topic model information","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Plot model summary 7 frequent words per topic. Print summary() topic model explore sets words characterize 10 topics.","code":"# stm plot() teh topic model provides a summary of topic proportions # print a summary() of the topic model"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"understanding-and-labeling-topics","dir":"Articles","previous_headings":"Exercise tasks","what":"Understanding and labeling topics","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Create word clouds 10 topics using 30 words highest probability per topic. Remove term “biodiversity” display.","code":"# word clouds are a useful first step to arrive at summary labels for topics"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"covariate-effects","dir":"Articles","previous_headings":"Exercise tasks","what":"Covariate effects","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Print regression tables selected topics.","code":"# print a summary() of effects"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"publication-year","dir":"Articles","previous_headings":"Exercise tasks > Covariate effects","what":"Publication year","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Use stm plot method create plot shows effect publication year topical prevalence Topic 4 Topic 8. Annotate probable terms. Alternatively, stminsights package used extract regression information stm effects object create customized charts.","code":"# stm plot offers various different plot options for covariate effects # stminsights allows to get effects in a format suitable for ggplot2"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"publication-status-effect","dir":"Articles","previous_headings":"Exercise tasks > Covariate effects","what":"Publication status effect","title":"Exercise 1: Topic modeling biodiversity preprints","text":"also incoporated publication status model (covariate is_published). Using stm plot method explore effect treatment “published” topical prevalence. Compare topical prevalence effect covariate is_published Topic 4.","code":"# stm plot offers various different plotoptions for covariate effects # stm plot offers various different plotoptions for covariate effects"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"combination-of-publication-status-and-publication-year","dir":"Articles","previous_headings":"Exercise tasks > Covariate effects","what":"Combination of publication status and publication year","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Finally, can also explore combined effect covariates; assumed interacting effect two covariates is_published year. Using stm plot function explore combined interacting covariate effect Topic 4. , stminsights can used retrieve information create customized visualizations combined covariate effect.","code":"# stminsights allows to get effects in a format suitable for ggplot2"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"topic-correlations","dir":"Articles","previous_headings":"Exercise tasks > Exploring the topic structure","what":"Topic correlations","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Finally, retrieve topic correlations matrix plot cooccurrence network.","code":"# topic correlations retrieved with stm"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"getting-the-document-data-1","dir":"Articles","previous_headings":"Solution","what":"Getting the document data","title":"Exercise 1: Topic modeling biodiversity preprints","text":"assume created local copy preprint data run analysis (see information code samples “Getting document data” vignette(\"covid-preprint-topics\")).","code":"load(url(\"PREPRINT_RDATA_LOCATION_HERE\"))"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"cleaning-filtering-and-annotating-the-data-1","dir":"Articles","previous_headings":"Solution","what":"Cleaning, filtering and annotating the data","title":"Exercise 1: Topic modeling biodiversity preprints","text":"example planning explore whether publication status influences topic prevalence. therefore adapt time range consider preprints added 2017 2021. reduce subset preprints reference term ‘biodiversity’ either preprint title abstract.","code":"library(dplyr) library(stringr)  preprints_cleaned <- preprints_raw %>%   group_by(doi) %>%   filter(version == max(version)) %>%   ungroup() %>%   distinct(doi, .keep_all = TRUE)  preprints <- preprints_cleaned %>%   mutate(published = stringr::str_trim(published)) %>%   mutate(published = na_if(published, \"NA\")) %>%   mutate(is_published = as.numeric(!is.na(published))) %>%   mutate(is_published = case_when(is_published == 1 ~ \"published\",                                   is_published == 0 ~ \"not published\",                                   TRUE ~ \"undefined\")) %>%   mutate(year = lubridate::year(date)) %>%   filter(year >= 2017 & year <= 2021) %>%    select(doi, server, title, abstract, date, year, version, is_published)  keywords <- c(\"biodiversity\")  search_pattern <- stringr::regex(paste(keywords, collapse = \"|\"),                                   ignore_case = TRUE)  biodiv_preprints <- preprints %>%   filter(stringr::str_detect(title, pattern = search_pattern) |            stringr::str_detect(abstract, pattern = search_pattern))"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"create-a-corpus-1","dir":"Articles","previous_headings":"Solution > Preparing and preprocessing the documents for text analysis","what":"Create a corpus","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Create corpus explore properties.","code":"library(quanteda)  pubs_corpus <- biodiv_preprints %>%   quanteda::corpus(docid_field = \"doi\", text_field = \"abstract\")  # pubs_corpus # Corpus consisting of 29,692 documents and 6 docvars."},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"tokenize-and-preprocess-1","dir":"Articles","previous_headings":"Solution > Preparing and preprocessing the documents for text analysis","what":"Tokenize and preprocess","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Tokenize applying steps Covid preprint example.","code":"pubs_tokens <- pubs_corpus %>%   quanteda::tokens(remove_punct = TRUE,                    remove_symbols = TRUE,                    remove_numbers = TRUE,                    remove_url = TRUE,                    remove_separators = TRUE,                    split_hyphens = TRUE)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"create-a-document-feature-matrix-1","dir":"Articles","previous_headings":"Solution > Preparing and preprocessing the documents for text analysis","what":"Create a Document-feature matrix","title":"Exercise 1: Topic modeling biodiversity preprints","text":"","code":"pubs_dfm <- pubs_tokens %>%   quanteda::dfm()"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"filter-terms-and-documents-1","dir":"Articles","previous_headings":"Solution > Preparing and preprocessing the documents for text analysis","what":"Filter terms and documents","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Remove stopwords document-feature-matrix. Explore properties. Filter tokens documents applying approach Covid preprint example.","code":"pubs_dfm <- pubs_dfm %>%   quanteda::dfm_remove(pattern = quanteda::stopwords(\"english\")) #%>%   #quanteda::dfm_wordstem() pubs_dfm <- pubs_dfm %>%   quanteda::dfm_remove(min_nchar = 2) %>%   quanteda::dfm_trim(min_docfreq = 2, docfreq_type = \"count\") %>%   quanteda::dfm_subset(quanteda::ntoken(.) > 4)"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"fitting-the-stm-topic-model-1","dir":"Articles","previous_headings":"Solution > Topic modeling","what":"Fitting the STM topic model","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Fit stm topic model 10 topics prepared data. model consider interacting effect covariates is_published publication year topical prevalence. Apply seed argument value 9868467.","code":"library(stm)  biodiv_stm_docs <- quanteda::convert(pubs_dfm, to = \"stm\")  biodiv_model_K10 <- stm(documents = biodiv_stm_docs$documents,                     vocab = biodiv_stm_docs$vocab,                     data = biodiv_stm_docs$meta,                     prevalence = ~ is_published * year,                     K = 10,                     verbose = TRUE,                     seed = seed_stm)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"estimating-the-effect-of-document-covariates-1","dir":"Articles","previous_headings":"Solution > Topic modeling","what":"Estimating the effect of document covariates","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Evaluate effect previously chosen topic prevalence covariates topics. concludes fitting model. following sections step sample exploration topic model.","code":"biodiv_effect_K10 <- estimateEffect(1:10 ~ is_published * year,                                    stmobj = biodiv_model_K10,                                    metadata = biodiv_stm_docs$meta)"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"basic-topic-model-information-1","dir":"Articles","previous_headings":"Solution > Analysing and interpreting the topic model","what":"Basic topic model information","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Plot model summary 7 frequent words per topic.  Print summary() topic model explore sets words characterize 10 topics.","code":"plot(biodiv_model_K10, n = 7) summary(biodiv_model_K10) ># A topic model with 10 topics, 1495 documents and a 8838 word dictionary. ># Topic 1 Top Words: >#       Highest Prob: species, fish, marine, invasive, biodiversity, native, river  >#       FREX: coral, reefs, lakes, fisheries, reef, fishing, ocean  >#       Lift: advection, afdw, aggregations, aleutian, ampat, amphipods, andaman  >#       Score: fish, reef, islands, coral, fisheries, fishing, sea  ># Topic 2 Top Words: >#       Highest Prob: data, species, biodiversity, can, information, using, research  >#       FREX: user, users, automated, learning, databases, images, algorithms  >#       Lift: cheilostome, cnns, crux, digitized, disparities, dnn, echolocating  >#       Score: images, users, user, algorithms, pipeline, learning, students  ># Topic 3 Top Words: >#       Highest Prob: host, disease, biodiversity, populations, microbiota, human, infection  >#       FREX: infection, pathogen, virus, viruses, viral, diseases, infections  >#       Lift: antimicrobial, antimicrobials, attack, auxiliary, baits, brain, brood  >#       Score: infection, disease, host, pathogen, gut, microbiota, virus  ># Topic 4 Top Words: >#       Highest Prob: genetic, species, genome, populations, gene, population, genes  >#       FREX: snp, alleles, introgression, genome, genomic, genetic, genomes  >#       Lift: 3a, admixed, angustifolia, antibacterial, aureus, beak, beast  >#       Score: genome, genetic, genes, genomes, genomic, gene, speciation  ># Topic 5 Top Words: >#       Highest Prob: species, model, biodiversity, can, ecological, models, dynamics  >#       FREX: coexistence, competitive, theory, simulations, competition, stability, empirical  >#       Lift: abandon, absences, accumulates, aggressively, anchovy, archosaurs, assumes  >#       Score: competitive, theory, coexistence, competition, stability, simulations, preemption  ># Topic 6 Top Words: >#       Highest Prob: species, diversity, biodiversity, change, richness, climate, across  >#       FREX: climatic, gradients, biotic, turnover, climate, scales, richness  >#       Lift: arabia, bioregions, bryophyte, constantly, divide, endotherms, equivalence  >#       Score: richness, climate, elevational, phylogenetic, zeta, ldg, gradients  ># Topic 7 Top Words: >#       Highest Prob: plant, soil, diversity, communities, microbial, community, species  >#       FREX: mixtures, fire, soil, aboveground, amf, nitrogen, plant  >#       Lift: biodiv, conditioned, decomposer, exudate, fertilisation, microclimate, microsite  >#       Score: soil, microbial, grazing, bacterial, amf, mixtures, crop  ># Topic 8 Top Words: >#       Highest Prob: forest, forests, species, tree, cover, de, biodiversity  >#       FREX: forest, forests, en, de, plantations, la, es  >#       Lift: como, diversidad, landcover, que, una, vegetable, acacia  >#       Score: forest, forests, la, que, de, las, plantations  ># Topic 9 Top Words: >#       Highest Prob: conservation, species, biodiversity, areas, land, use, management  >#       FREX: iucn, socio, protected, lands, pas, conservation, nations  >#       Lift: eu, herpetofauna, pas, 30x30, abroad, accessing, achievements  >#       Score: protected, land, pas, iucn, lands, natura, conservation  ># Topic 10 Top Words: >#       Highest Prob: dna, edna, samples, species, metabarcoding, biodiversity, diversity  >#       FREX: edna, metabarcoding, samples, dna, primer, coi, biomonitoring  >#       Lift: 1the, acuta, asv, battery, benthos, bony, bruv  >#       Score: edna, metabarcoding, dna, samples, primer, coi, cristatus"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"understanding-and-labeling-topics-1","dir":"Articles","previous_headings":"Solution","what":"Understanding and labeling topics","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Create word clouds 10 topics using 30 words highest probability per topic. Remove term “biodiversity” display. Word clouds showing 30 probable terms per topic.","code":"library(tidyr) library(tibble)  # get the top FREX words frex_top20 <- as.data.frame(labelTopics(biodiv_model_K10, n = 25)$frex) %>%   rownames_to_column(var = \"topic\") %>%   pivot_longer(starts_with(\"V\"), values_to = \"term\") %>%   mutate(is_frex = 1) %>%   select(-name)  topic_words <- tidytext::tidy(biodiv_model_K10, matrix = \"beta\") %>%   #filter(!(term %in% c(\"sars\", \"cov\", \"covid\"))) %>%    mutate(topic = as.character(topic)) %>%   group_by(topic) %>%   arrange(-beta) %>%   slice_head(n = 30) %>%   mutate(beta_norm = (beta - min(beta)) / (max(beta) - min(beta))) %>%   ungroup() %>%   left_join(frex_top20, by = c(\"topic\", \"term\")) %>%   mutate(is_frex = ifelse(is.na(is_frex), \"0\", \"1\")) %>%   filter(!(term %in% c(\"biodiversity\"))) %>%   mutate(topic = paste(\"Topic\", topic))  ggplot(topic_words, aes(label = term, size = beta_norm, color = is_frex)) +   ggwordcloud::geom_text_wordcloud_area(shape = \"square\",                                         family = \"Arial\",                                         rm_outside = TRUE) +   scale_radius(range = c(4, 15)) +   scale_color_manual(values = c(\"0\" = \"black\", \"1\" = \"#D55E00\")) +    facet_wrap(~topic, ncol = 5)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"covariate-effects-1","dir":"Articles","previous_headings":"Solution","what":"Covariate effects","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Print regression tables selected topics.","code":"summary(biodiv_effect_K10) >#  ># Call: ># estimateEffect(formula = 1:10 ~ is_published * year, stmobj = biodiv_model_K10,  >#     metadata = biodiv_stm_docs$meta) >#  >#  ># Topic 1: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                -1.8353537 15.0212702  -0.122    0.903 ># is_publishedpublished      -6.8892185 19.4009636  -0.355    0.723 ># year                        0.0009505  0.0074377   0.128    0.898 ># is_publishedpublished:year  0.0034069  0.0096060   0.355    0.723 >#  >#  ># Topic 2: >#  ># Coefficients: >#                             Estimate Std. Error t value Pr(>|t|) ># (Intercept)                -5.960533  17.563209  -0.339    0.734 ># is_publishedpublished       4.712923  23.282832   0.202    0.840 ># year                        0.003004   0.008696   0.345    0.730 ># is_publishedpublished:year -0.002339   0.011528  -0.203    0.839 >#  >#  ># Topic 3: >#  ># Coefficients: >#                             Estimate Std. Error t value Pr(>|t|) ># (Intercept)                -2.008048  18.124735  -0.111    0.912 ># is_publishedpublished      -2.196859  22.838026  -0.096    0.923 ># year                        0.001028   0.008974   0.115    0.909 ># is_publishedpublished:year  0.001094   0.011308   0.097    0.923 >#  >#  ># Topic 4: >#  ># Coefficients: >#                             Estimate Std. Error t value Pr(>|t|) ># (Intercept)                10.232851  19.299787   0.530    0.596 ># is_publishedpublished      12.063924  23.713554   0.509    0.611 ># year                       -0.005024   0.009555  -0.526    0.599 ># is_publishedpublished:year -0.005957   0.011741  -0.507    0.612 >#  >#  ># Topic 5: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                 24.386740  18.678895   1.306    0.192 ># is_publishedpublished      -10.349536  23.454794  -0.441    0.659 ># year                        -0.012015   0.009248  -1.299    0.194 ># is_publishedpublished:year   0.005118   0.011613   0.441    0.659 >#  >#  ># Topic 6: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                13.9883568 17.2828097   0.809    0.418 ># is_publishedpublished       0.6578739 21.9122714   0.030    0.976 ># year                       -0.0068590  0.0085572  -0.802    0.423 ># is_publishedpublished:year -0.0003297  0.0108497  -0.030    0.976 >#  >#  ># Topic 7: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                -18.008227  18.557308  -0.970    0.332 ># is_publishedpublished       14.200894  23.228709   0.611    0.541 ># year                         0.008971   0.009189   0.976    0.329 ># is_publishedpublished:year  -0.007031   0.011502  -0.611    0.541 >#  >#  ># Topic 8: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                  6.727219  12.712950   0.529    0.597 ># is_publishedpublished      -12.271112  16.055352  -0.764    0.445 ># year                        -0.003299   0.006295  -0.524    0.600 ># is_publishedpublished:year   0.006071   0.007950   0.764    0.445 >#  >#  ># Topic 9: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|)   ># (Intercept)                -32.279524  19.237520  -1.678   0.0936 . ># is_publishedpublished        9.847501  25.168682   0.391   0.6957   ># year                         0.016055   0.009525   1.686   0.0921 . ># is_publishedpublished:year  -0.004887   0.012462  -0.392   0.6950   ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 10: >#  ># Coefficients: >#                             Estimate Std. Error t value Pr(>|t|) ># (Intercept)                 5.534270  18.305061   0.302    0.762 ># is_publishedpublished      -9.249323  22.103762  -0.418    0.676 ># year                       -0.002702   0.009063  -0.298    0.766 ># is_publishedpublished:year  0.004592   0.010944   0.420    0.675"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"publication-year-1","dir":"Articles","previous_headings":"Solution > Covariate effects","what":"Publication year","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Use stm plot method create plot shows effect publication year topical prevalence Topic 4 Topic 8. Annotate probable terms.  Alternatively, stminsights package used extract regression information stm effects object create customized charts.","code":"plot(biodiv_effect_K10,      covariate = \"year\",      method = \"continuous\",      model = biodiv_model_K10,      topics = c(4, 8),      xaxt = \"n\",      main = 'Effect of publication year on prevalence of Topic 4 (\"???\") and Topic 8 (\"???\")',      labeltype = \"prob\",      xlab = \"Publication year\") axis(1, at = c(\"2017\",\"2018\",\"2019\",\"2020\", \"2021\"), labels = c(2017, 2018, 2019, 2020, 2021)) library(stminsights)  year_effect <- get_effects(estimates = biodiv_effect_K10,                             variable = \"year\",                            type = \"continuous\")  year_effect %>%   mutate(topic = as.character(topic)) %>%   mutate(topic = paste(\"Topic\", topic)) %>%     ggplot(aes(x = value, y = proportion)) +       geom_line() +       geom_ribbon(aes(ymin = lower, ymax = upper),                    alpha = 0.2, linetype = 0)  +       xlab(\"Publication year\") +       ylab(\"Topic prevalence\") +       facet_wrap(~topic, ncol = 5) +       theme_minimal()"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"publication-status-effect-1","dir":"Articles","previous_headings":"Solution > Covariate effects","what":"Publication status effect","title":"Exercise 1: Topic modeling biodiversity preprints","text":"also incoporated publication status model (covariate is_published). Using stm plot method explore effect treatment “published” topical prevalence.  Compare topical prevalence effect covariate is_published Topic 4.","code":"plot(biodiv_effect_K10,       covariate = \"is_published\",      #topics = c(9, 10, 16, 1),      model = biodiv_model_K10,       method = \"difference\",      cov.value1 = \"published\", cov.value2 = \"not published\",      xlab = \"higher prevalence in unpublished ... higher prevalence in published\",      #xlim = c(-0.19, 0.1),      #labeltype = \"prob\",      main = \"Effect of preprint server (treatment 'published')\") plot(biodiv_effect_K10,       covariate = \"is_published\",      topics = c(4),      model = biodiv_model_K10,        method = \"pointestimate\",      xlab = \"Topical prevalence\",      #xlim = c(-0.04, 0.2),      #labeltype = \"prob\",      main = \"Effect of preprint 'is_published' covariate for Topic 4\")"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"combination-of-publication-status-and-publication-year-1","dir":"Articles","previous_headings":"Solution > Covariate effects","what":"Combination of publication status and publication year","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Finally, can also explore combined effect covariates; assumed interacting effect two covariates is_published year. Using stm plot function explore combined interacting covariate effect Topic 4.  , stminsights can used retrieve information create customized visualizations combined covariate effect.","code":"published_effect <- get_effects(biodiv_effect_K10,                                  variable = \"year\", type = \"continuous\",                                  moderator = \"is_published\", modval = \"published\")  unpublished_effect <- get_effects(biodiv_effect_K10,                                   variable = \"year\", type = \"continuous\",                                    moderator = \"is_published\", modval = \"not published\")  is_published_effects <- bind_rows(published_effect, unpublished_effect)  is_published_effects %>%   mutate(topic = as.character(topic)) %>%   mutate(topic = paste(\"Topic\", topic)) %>%     ggplot(aes(x = value, y = proportion, color = moderator,                group = moderator, fill = moderator)) +       geom_line() +       geom_ribbon(aes(ymin = lower, ymax = upper,                        fill = moderator), alpha = 0.2, linetype = 0) +       xlab(\"Publication year\") +       ylab(\"Topic prevalence\") +       facet_wrap(~topic, ncol = 5) +       theme_minimal() +       theme(legend.position = \"bottom\")"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"topic-correlations-1","dir":"Articles","previous_headings":"Solution > Exploring the topic structure","what":"Topic correlations","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Finally, retrieve topic correlations matrix plot cooccurrence network.","code":"covid_topic_correlations <- topicCorr(biodiv_model_K10, cutoff = 0.001)  plot(covid_topic_correlations)"},{"path":"https://sdaume.github.io/srcquantcourse/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Stefan Daume. Author, maintainer.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Daume S (2024). srcquantcourse: Scripts Exercises SRC Quantitative Methods PhD Course. R package version 0.0.0.9000, https://github.com/sdaume/srcquantcourse, https://sdaume.github.io/srcquantcourse.","code":"@Manual{,   title = {srcquantcourse: Scripts and Exercises for the SRC Quantitative Methods PhD Course},   author = {Stefan Daume},   year = {2024},   note = {R package version 0.0.0.9000, https://github.com/sdaume/srcquantcourse},   url = {https://sdaume.github.io/srcquantcourse}, }"},{"path":"https://sdaume.github.io/srcquantcourse/index.html","id":"srcquantcourse","dir":"","previous_headings":"","what":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","title":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","text":"goal srcquantcourse provide sample analysis, replication scripts exercises data analysis module SRC Quantitative Methods PhD Course; part module concentrates probabilistic topic modelling.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","text":"can install development version srcquantcourse GitHub : Alternatively, clone repo (https://github.com/sdaume/srcquantcourse) order work modify scripts.","code":"# install.packages(\"devtools\") devtools::install_github(\"sdaume/srcquantcourse\")"},{"path":"https://sdaume.github.io/srcquantcourse/index.html","id":"license-credits-and-acknowledgements","dir":"","previous_headings":"","what":"License, credits and acknowledgements","title":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","text":"package shared MIT License. package relies several R packages listed package DESCRIPTION accompanying scripts. work packages’ authors hereby gratefully acknowledged. illustrate methods covered package preprint meta-data bioRxiv medRxiv used. preprint servers provide API access preprints explicitly intended support text mining; hereby gratefully acknowledged. actual preprints shared package, scripts utilizing medrxivr package provided obtain preprint data replicate results. package developed support education research Stockholm Resilience Centre; research benefited funding Swedish Research Council Sustainable Development (Formas).","code":""},{"path":"https://sdaume.github.io/srcquantcourse/index.html","id":"disclaimer","dir":"","previous_headings":"","what":"Disclaimer","title":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","text":"package author(s) associated bioRxiv medRxiv. package developed reusable tool education author(s) research comes guarantee correctness results included package functions.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_effect_K10.html","id":null,"dir":"Reference","previous_headings":"","what":"An STM regression object for a topic model with 10 topics — biodiv_effect_K10","title":"An STM regression object for a topic model with 10 topics — biodiv_effect_K10","text":"package data set provides results applying stm::estimateEffect() function included biodiv_model_K10 topic model object.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_effect_K10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An STM regression object for a topic model with 10 topics — biodiv_effect_K10","text":"","code":"biodiv_effect_K10"},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_effect_K10.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An STM regression object for a topic model with 10 topics — biodiv_effect_K10","text":"STM regression object","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_model_K10.html","id":null,"dir":"Reference","previous_headings":"","what":"An STM topic model with 10 topics — biodiv_model_K10","title":"An STM topic model with 10 topics — biodiv_model_K10","text":"package data set provides sample STM topic model K = 10 topics (see stm::stm()). model fit bioRxiv medRxiv preprints 2017 2021 contain term 'biodiversity' title abstract. model fit respective publication status publication year topic prevalence covariates. included biodiv_effect_K10 dataset captures regression parameters document covariates.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_model_K10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An STM topic model with 10 topics — biodiv_model_K10","text":"","code":"biodiv_model_K10"},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_model_K10.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An STM topic model with 10 topics — biodiv_model_K10","text":"STM topic model object","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_effect_K20.html","id":null,"dir":"Reference","previous_headings":"","what":"An STM regression object for a topic model with 20 topics — covid_effect_K20","title":"An STM regression object for a topic model with 20 topics — covid_effect_K20","text":"package data set provides results applying stm::estimateEffect() function included covid_model_K20 topic model object.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_effect_K20.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An STM regression object for a topic model with 20 topics — covid_effect_K20","text":"","code":"covid_effect_K20"},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_effect_K20.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An STM regression object for a topic model with 20 topics — covid_effect_K20","text":"STM regression object","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_model_K20.html","id":null,"dir":"Reference","previous_headings":"","what":"An STM topic model with 20 topics — covid_model_K20","title":"An STM topic model with 20 topics — covid_model_K20","text":"package data set provides sample STM topic model K = 20 topics (see stm::stm()). model fit bioRxiv medRxiv preprints 2020 2023 contain terms 'sars-cov' 'covid' title abstract. model fit respective preprint server publication year topic prevalence covariates. included covid_effect_K20 dataset captures regression parameters document covariates.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_model_K20.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An STM topic model with 20 topics — covid_model_K20","text":"","code":"covid_model_K20"},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_model_K20.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An STM topic model with 20 topics — covid_model_K20","text":"STM topic model object","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/srcquantcourse-package.html","id":null,"dir":"Reference","previous_headings":"","what":"srcquantcourse: Scripts and Exercises for the SRC Quantitative Methods PhD Course — srcquantcourse-package","title":"srcquantcourse: Scripts and Exercises for the SRC Quantitative Methods PhD Course — srcquantcourse-package","text":"package collects scripts, data exercises notes 2024 SRC Quantitative Methods PhD course.","code":""},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/reference/srcquantcourse-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"srcquantcourse: Scripts and Exercises for the SRC Quantitative Methods PhD Course — srcquantcourse-package","text":"Maintainer: Stefan Daume stefan.daume@su.se (ORCID)","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/topicmodel_evaluations.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluation results for topic models with different K — topicmodel_evaluations","title":"Evaluation results for topic models with different K — topicmodel_evaluations","text":"convenience dataset include results evaluating topic models different topic numbers (K) thematic subsets bioRxiv medRxiv preprints. Scripts run actual evaluations included package repo.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/topicmodel_evaluations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluation results for topic models with different K — topicmodel_evaluations","text":"","code":"topicmodel_evaluations"},{"path":"https://sdaume.github.io/srcquantcourse/reference/topicmodel_evaluations.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Evaluation results for topic models with different K — topicmodel_evaluations","text":"dataframe four variables","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/topicmodel_evaluations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluation results for topic models with different K — topicmodel_evaluations","text":"dataset specifies preprint subset, used K, type evaluation metric value metric.","code":""}]
