[{"path":"https://sdaume.github.io/srcquantcourse/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Stefan Daume Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example: Topic modelling Covid preprints","text":"example topic modelling analysis using Structural Topic Model (STM) (Roberts, Stewart, Tingley 2019) explore subset bioRxiv medRxiv preprints covering research related Covid-19. medRxiv website actually provides access dedicated collection preprints medRxix bioRxiv covering COVID-19 SARS-CoV-2. however work whole preprint collection create subset using keyword matching. Note analysis intended illustrate method topic modeling. complete analysis sample preprints detailed like feature larger number topics. document assumes familiarity Structural Topic Modeling (STM). Please consult stm package vignette (Roberts, Stewart, Tingley 2019) background.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"getting-the-document-data","dir":"Articles","previous_headings":"","what":"Getting the document data","title":"Example: Topic modelling Covid preprints","text":"bioRxiv medRxiv servers provide API access retrieve preprint meta-data. One option access API use medrxivr package. code snippet example collect bioRxiv preprint meta-data year 2015. package setup support exploring different thematic preprint subsets assumes usage preprints servers published 2013 2023. data can shared package usage API terms bioRxiv/medRxiv permit redistribution rehosting complete data; therefore package provides scripts collect clean data order replicate analysis (check /data-raw package repository). documented examples assume obtained data created local copy replication analyses. code allow . NOTE time writing returned dataset 365526 records. Retrieving data take several hours. replicating analysis like use bioRxiv/medRxiv API responsibly. Consider collecting smaller datasets (example shown example require preprints 2020 2023). Alternatively, use bulk snapshot detailed . addition 15 meta-data variables returned via API code adds server variable indicate origin preprint. important variable examples shown .","code":"library(medrxivr)  biorxiv_raw <- mx_api_content(server = \"biorxiv\",                               from_date = \"2015-12-01\",                               to_date = \"2015-12-31\") library(dplyr) library(medrxivr)  # get publications from medRxiv and bioRxiv pubs_biorxiv_raw <- medrxivr::mx_api_content(server = \"biorxiv\",                                              #from_date = \"2019-01-01\",                                              to_date = \"2023-12-31\")  pubs_medrxiv_raw <- medrxivr::mx_api_content(server = \"medrxiv\",                                              #from_date = \"2019-01-01\",                                              to_date = \"2023-12-31\")  pubs_biorxiv_raw <- pubs_biorxiv_raw %>%   mutate(server = \"biorxiv\")  pubs_medrxiv_raw <- pubs_medrxiv_raw %>%   mutate(server = \"medrxiv\")  preprints_raw <- dplyr::bind_rows(pubs_biorxiv_raw, pubs_medrxiv_raw)  save(preprints_raw, file = \"./data-raw/preprints_raw.Rdata\")"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"cleaning-filtering-and-annotating-the-data","dir":"Articles","previous_headings":"","what":"Cleaning, filtering and annotating the data","title":"Example: Topic modelling Covid preprints","text":"first step raw preprint data cleaned. Specifically, want retain one unique record per preprint, multiple versions unique doi may exist. retain latest version per DOI also ensure duplicate dois. crucial need unique identifier document want include topic modelling. Next annotate data additional variables, specifically want reduce publication date publication year, add additional variable is_published, inferred published variable. latter provides DOI journal preprint published peer review. also limit data preprints 2020 2023 (analysis Covid topics preprints prior 2020 relevant), retain variables may want explore document covariates, .e. document properties potentially influence prevalence topics. Finally, define keywords reduce preprint set preprints contain one keywords either title abstract, resulting subset 29692 publications.","code":"library(dplyr)  preprints_cleaned <- preprints_raw %>%   group_by(doi) %>%   filter(version == max(version)) %>%   ungroup() %>%   distinct(doi, .keep_all = TRUE) preprints <- preprints_cleaned %>%   mutate(published = stringr::str_trim(published)) %>%   mutate(published = na_if(published, \"NA\")) %>%   mutate(is_published = as.numeric(!is.na(published))) %>%   mutate(is_published = case_when(is_published == 1 ~ \"published\",                                   is_published == 0 ~ \"not published\",                                   TRUE ~ \"undefined\")) %>%   mutate(year = lubridate::year(date)) %>%   filter(year >= 2020 & year <= 2023) %>%    select(doi, server, title, abstract, date, year, version, is_published) library(stringr)  keywords <- c(\"sars-cov\", \"covid\")  search_pattern <- stringr::regex(paste(keywords, collapse = \"|\"),                                   ignore_case = TRUE)  covid_preprints <- preprints %>%   filter(stringr::str_detect(title, pattern = search_pattern) |            stringr::str_detect(abstract, pattern = search_pattern))"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"preparing-and-preprocessing-the-documents-for-text-analysis","dir":"Articles","previous_headings":"","what":"Preparing and preprocessing the documents for text analysis","title":"Example: Topic modelling Covid preprints","text":"order analyze preprints stm package need create representation documents document meta-data stm can utilize. stm offers built-methods support (see specifically textProcessor() prepDocuments() methods (Roberts, Stewart, Tingley 2019)). use instead quanteda package (Benoit et al. 2018) provides broad range methods text pre-processing analysis, creating formats also supported stm.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"create-a-corpus","dir":"Articles","previous_headings":"Preparing and preprocessing the documents for text analysis","what":"Create a corpus","title":"Example: Topic modelling Covid preprints","text":"First, create corpus object dataframe preprints. corpus essentially library documents used next steps. specifies variable used uniquely identify documents variable holds textual content (preprint abstracts) processed. Echoing corpus provide basic information. variables original dataframe interpreted included document metadata (‘docvars’), later included STM topic modelling process.","code":"library(quanteda)  pubs_corpus <- covid_preprints %>%   quanteda::corpus(docid_field = \"doi\", text_field = \"abstract\")  # pubs_corpus # Corpus consisting of 29,692 documents and 6 docvars."},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"tokenize-and-preprocess","dir":"Articles","previous_headings":"Preparing and preprocessing the documents for text analysis","what":"Tokenize and preprocess","title":"Example: Topic modelling Covid preprints","text":"analysis corpus documents tokenized, .e. processing texts broken semantic units relevant analysis. common approach interpret word (typically designated whitespaces punctuation) token. applied well. quanteda offers several alternative approaches. Instead individual words, sequences words (n-grams) example used. tokenization method also provides several options preprocessing filtering tokens. example, tokenizing, simultaneously remove punctuation, numbers, special symbols URLs. Furthermore, split words containing hyphens, word like social-ecological thus split two individual tokens (social ecological). text preprocessing choices strongly influence results text analysis thoroughly explained, carefully evaluated ideally based theory (see (Denny Spirling 2018)).","code":"pubs_tokens <- pubs_corpus %>%   quanteda::tokens(remove_punct = TRUE,                    remove_symbols = TRUE,                    remove_numbers = TRUE,                    remove_url = TRUE,                    remove_separators = TRUE,                    split_hyphens = TRUE)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"create-a-document-feature-matrix","dir":"Articles","previous_headings":"Preparing and preprocessing the documents for text analysis","what":"Create a Document-feature matrix","title":"Example: Topic modelling Covid preprints","text":"tokens object used create document-feature matrix. statistical analysis reduces tokens matrix documents (rows) unique terms (columns) counts number occurrences term document. quanteda captures features supports general options terms (see quanteda documentation details).","code":"pubs_dfm <- pubs_tokens %>%   quanteda::dfm()"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"filter-terms-and-documents","dir":"Articles","previous_headings":"Preparing and preprocessing the documents for text analysis","what":"Filter terms and documents","title":"Example: Topic modelling Covid preprints","text":"followed (optional) processing filtering steps. common option example — reduce size data assist interpretation — removal -called stopwords (e.g. “”, “”, “” etc). step omitted reducing words (terms) word stem. stemming algorithm (several available) reduces words word stem. terms “universal”, “university” “universe” example reduced word stem “univers”; example indicates approach may require careful consideration. Stemming advantage potentially reduce size matrix substantially. options may considered reduce noise /size matrix. following code removes example terms (features) consist one character, terms appear least two different documents, furthermore remove documents contain least 5 tokens. example drops one document reduces number retained features half.","code":"pubs_dfm <- pubs_dfm %>%   quanteda::dfm_remove(pattern = quanteda::stopwords(\"english\")) #%>%   #quanteda::dfm_wordstem() # echo the result > pubs_dfm  Document-feature matrix of: 29,692 documents, 82,472 features (99.87% sparse) and 6 docvars.                 features docs             nitric oxide synthesised three isoforms synthases viz nnos neurons enos   10.1101/038398      6     6           1     1        1         1   1    1       2    1   10.1101/058511      0     0           0     0        0         0   0    0       0    0   10.1101/292979      0     0           0     2        0         0   0    0       0    0   10.1101/402370      0     0           0     0        0         0   0    0       0    0   10.1101/420737      0     0           0     0        0         0   0    0       0    0   10.1101/596700      0     0           0     0        0         0   0    0       0    0 [ reached max_ndoc ... 29,686 more documents, reached max_nfeat ... 82,462 more features ] pubs_dfm <- pubs_dfm %>%   quanteda::dfm_remove(min_nchar = 2) %>%   quanteda::dfm_trim(min_docfreq = 2, docfreq_type = \"count\") %>%   quanteda::dfm_subset(quanteda::ntoken(.) > 4) # echo the result > pubs_dfm  Document-feature matrix of: 29,691 documents, 37,093 features (99.72% sparse) and 6 docvars.                 features docs             nitric oxide synthesised three isoforms synthases viz neurons enos endothelial   10.1101/038398      6     6           1     1        1         1   1       2    1           2   10.1101/058511      0     0           0     0        0         0   0       0    0           0   10.1101/292979      0     0           0     2        0         0   0       0    0           0   10.1101/402370      0     0           0     0        0         0   0       0    0           0   10.1101/420737      0     0           0     0        0         0   0       0    0           0   10.1101/596700      0     0           0     0        0         0   0       0    0           0 [ reached max_ndoc ... 29,685 more documents, reached max_nfeat ... 37,083 more features ]"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"fitting-the-stm-topic-model","dir":"Articles","previous_headings":"Topic modeling","what":"Fitting the STM topic model","title":"Example: Topic modelling Covid preprints","text":"key input topic modelling algorithm number topics (K) model fit , set 20 (see separate document discussion suitable choices number topics). fitting topic model convert document-feature matrix native STM format. order fit topic model stm() function need set documents, vocabulary documents composed dataframe specifying values document meta-data variables (data) can used process “covariates” might influence prevalence topics document. example , ask stm incorporate origin document (server) publication year fitting topic model. argument prevalence = ~ server * s(year) expresses assume prevalence topics document influenced two variables, also interact, .e. work hypothesis different temporal trends expected documents published either two preprint servers1. consideration covariates optional. omitted model reduces Correlated Topic Model (Blei Lafferty 2007; Roberts, Stewart, Tingley 2019). also supply seed, allows replicate results topic modeling.","code":"library(stm)  covid_stm_docs <- quanteda::convert(pubs_dfm, to = \"stm\")  covid_model_K20 <- stm(documents = covid_stm_docs$documents,                        vocab = covid_stm_docs$vocab,                        data = covid_stm_docs$meta,                        prevalence = ~ server * s(year),                        K = 20,                        verbose = TRUE,                        seed = 9868467)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"estimating-the-effect-of-document-covariates","dir":"Articles","previous_headings":"Topic modeling","what":"Estimating the effect of document covariates","title":"Example: Topic modelling Covid preprints","text":"model converged can estimate effect document covariates topic prevalence. estimateEffect() function allows run regressions based formula specified first argument. identical formula used fitting topic model, regressions run 20 topics. metadata used previously needs supplied function addition topic model object. concludes fitting model. following sections step sample exploration topic model.","code":"covid_effect_K20 <- estimateEffect(1:20 ~ server * s(year),                                    stmobj = covid_model_K20,                                    metadata = covid_stm_docs$meta)"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"basic-topic-model-information","dir":"Articles","previous_headings":"Analysing and interpreting the topic model","what":"Basic topic model information","title":"Example: Topic modelling Covid preprints","text":"topic model defined two matrices capture probability distributions topics documents (gamma matrix) words (terms) topics (beta matrix). can start exploring built-functions stm. plot() function plots chart showing topic proportions topics model. topic identified unique ID (1-20) plot five words (terms) highest probability associated given topic. gives early indication distinct latent topics analysed subset preprints.  summary() function provides detailed view topics can help begin interpreting labeling 20 topics. Specifically, output shows four different sets words associated topic. ‘Highest Prob’ lists words highest probability associated topic. comparison different topics highlights term covid high probability several topics. list ‘FREX’ words summarizes words frequent exclusive topic, .e. characterize topic comparison topics (consult stm::labelTopics() details well Lift Score word sets).","code":"plot(covid_model_K20, n = 5) summary(covid_model_K20) ># A topic model with 20 topics, 29691 documents and a 37093 word dictionary. ># Topic 1 Top Words: >#       Highest Prob: model, can, covid, transmission, epidemic, data, disease  >#       FREX: npis, mathematical, compartmental, scenarios, seir, reproduction, sir  >#       Lift: 1we, abms, ao_scplowbstractc_scplowas, apt, artefact, asilv, asymptotically  >#       Score: distancing, social, epidemic, reproduction, npis, model, r0  ># Topic 2 Top Words: >#       Highest Prob: cov, sars, drug, antiviral, activity, drugs, covid  >#       FREX: src, figdir, o_linksmallfig, c_fig, m_fig, o_fig, gif  >#       Lift: k777, gif, pmmov, wwtps, 13k, 17k, 18k  >#       Score: mpro, antiviral, drug, inhibitors, protease, drugs, compounds  ># Topic 3 Top Words: >#       Highest Prob: covid, risk, age, mortality, ci, associated, years  >#       FREX: hispanic, ethnicity, pregnant, racial, black, smoking, preterm  >#       Lift: 65s, asmr, assault, backgroundethnic, backgroundracial, backgroundsocio, brunt  >#       Score: ci, age, women, mortality, ethnicity, aor, hispanic  ># Topic 4 Top Words: >#       Highest Prob: covid, health, pandemic, mental, social, study, survey  >#       FREX: loneliness, emotional, attitude, depression, insecurity, mental, anxiety  >#       Lift: insecurity, accelerometers, amhara, angry, anovas, asd, asleep  >#       Score: mental, anxiety, depression, respondents, social, psychological, students  ># Topic 5 Top Words: >#       Highest Prob: sars, cov, infection, testing, transmission, cases, children  >#       FREX: ifr, seroprevalence, schools, school, contacts, household, attack  >#       Lift: inmates, 19y, 35y, 39y, 9a, abidjan, addscovid  >#       Score: school, seroprevalence, children, schools, household, transmission, testing  ># Topic 6 Top Words: >#       Highest Prob: cov, sars, virus, viral, coronavirus, respiratory, infection  >#       FREX: bats, cats, deer, animals, covs, wildlife, hcov  >#       Lift: cats, 5x106, aav6, aegyptiacus, aethiops, affinis, agm  >#       Score: cov, sars, mice, rna, viruses, coronaviruses, animals  ># Topic 7 Top Words: >#       Highest Prob: patients, covid, hospital, disease, clinical, severe, admission  >#       FREX: acei, admission, arbs, admitted, icu, aki, aceis  >#       Lift: 1.1x109, 2020r1g1a1a01006229, 2l, 4.0x109, 40y, ahmad, ahrq  >#       Score: patients, admission, icu, hospital, admitted, ci, hospitalized  ># Topic 8 Top Words: >#       Highest Prob: covid, cases, countries, number, deaths, data, pandemic  >#       FREX: cfr, italy, cities, country, countries, fatality, china  >#       Lift: 1000m, 1th, 55th, abysmally, abyss, adhanom, adminstat  >#       Score: countries, cases, lockdown, deaths, country, cfr, daily  ># Topic 9 Top Words: >#       Highest Prob: protein, binding, spike, sars, cov, ace2, rbd  >#       FREX: conformational, cryo, conformation, glycans, conformations, nanobodies, residues  >#       Lift: 13c, 6lzg, 6m0j, 6vw1, 6vxx, aabpu, abdab  >#       Score: binding, rbd, protein, spike, ace2, proteins, epitopes  ># Topic 10 Top Words: >#       Highest Prob: data, can, learning, covid, using, model, based  >#       FREX: aerosol, n95, aerosols, respirators, decontamination, airborne, machine  >#       Lift: elastomeric, forehead, papr, radiomics, exhaled, singing, 0.3m  >#       Score: learning, masks, aerosol, machine, respirators, n95, mask  ># Topic 11 Top Words: >#       Highest Prob: vaccine, vaccination, covid, middle, vaccines, dot, dose  >#       FREX: hesitancy, dot, vaccinate, middle, hesitant, rollout, ve  >#       Lift: #949850, acceptant, adjrr, aesis, amparo, analysesthe, andersen  >#       Score: vaccination, vaccine, dot, booster, dose, vaccinated, middle  ># Topic 12 Top Words: >#       Highest Prob: studies, care, covid, health, research, data, pandemic  >#       FREX: reviews, telemedicine, preprints, scoping, articles, blacksquare, publications  >#       Lift: preprints, 1.2m, aas, abbreviating, accustomed, activists, advisor  >#       Score: review, care, services, articles, reviews, pubmed, service  ># Topic 13 Top Words: >#       Highest Prob: sars, cov, genome, mutations, sequencing, viral, variants  >#       FREX: phylogenetic, gisaid, clades, wgs, genomes, genomic, haplotype  >#       Lift: clades, snvs, 1.1.7s, 11083g, 14408c, 17del, 20a  >#       Score: mutations, genome, wastewater, genomes, sequences, sequencing, genomic  ># Topic 14 Top Words: >#       Highest Prob: cells, cell, sars, cov, expression, infection, ace2  >#       FREX: autophagy, mirnas, mirna, at2, ifns, ciliated, scrna  >#       Lift: 25hc, angiotensinogen, antagonizes, apcs, arf6, asgr1, at2s  >#       Score: cells, expression, ace2, cell, genes, epithelial, tmprss2  ># Topic 15 Top Words: >#       Highest Prob: antibody, sars, cov, antibodies, igg, responses, vaccine  >#       FREX: iga, bau, igg, humoral, immunogenicity, as03, reactogenicity  >#       Lift: 1x1011, 28d, 30ug, ad26cov2, addas03, adhu5, atellica  >#       Score: igg, antibody, antibodies, neutralizing, rbd, vaccine, spike  ># Topic 16 Top Words: >#       Highest Prob: sars, cov, pcr, samples, rt, test, testing  >#       FREX: ag, rdt, rdts, lod, rt, panbio, kits  >#       Lift: poct, cobas, panbio, #yomecorono, 1.6x104, 10min, 15min  >#       Score: rt, pcr, assay, samples, saliva, detection, assays  ># Topic 17 Top Words: >#       Highest Prob: variants, omicron, variant, delta, ba, cov, sars  >#       FREX: omicron, ba, xbb, subvariants, delta, bq, voc  >#       Lift: 1.5s, 129s2, 1f11, 2.86s, 3b8, 417n, 75d30121c11061  >#       Score: omicron, ba, variants, variant, delta, mutations, voc  ># Topic 18 Top Words: >#       Highest Prob: covid, patients, disease, severe, immune, inflammatory, associated  >#       FREX: autoantibodies, ipf, balf, neutrophils, il, fibrosis, autoantibody  >#       Lift: 18f, 24hr, a2ar, aab, actinobacteria, activin, adiponectin  >#       Score: inflammatory, il, patients, cytokine, inflammation, cytokines, endothelial  ># Topic 19 Top Words: >#       Highest Prob: patients, treatment, covid, group, days, day, trial  >#       FREX: placebo, randomized, hcq, soc, azithromycin, arm, tocilizumab  >#       Lift: 200mg, 400mg, 500mg, 600mg, 800mg, aureobasidium, ayush  >#       Score: placebo, hcq, trial, patients, randomized, tocilizumab, hydroxychloroquine  ># Topic 20 Top Words: >#       Highest Prob: covid, symptoms, long, workers, infection, participants, study  >#       FREX: hcws, taste, smell, hcw, fatigue, workers, headache  >#       Lift: chemesthetic, dirty, eyewear, firefighters, ohs, principality, psychophysical  >#       Score: symptoms, hcws, workers, participants, symptom, hcw, fatigue"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"topic-document-and-term-topic-distributions","dir":"Articles","previous_headings":"Analysing and interpreting the topic model","what":"Topic-document and term-topic distributions","title":"Example: Topic modelling Covid preprints","text":"mentioned, topic model defined gamma (distribution topics words) beta (distribution terms topics) matrices. help tidytext package can extract dataframes detailed analysis. row following dataframe lists probability (gamma) given topic occurring given document2. Similarly, beta matrix (extracted dataframe) lists row probability (beta) given term occurring given topic. Starting beta matrix can create word clouds explore useful semantic labels topic.","code":"># Rows: 593,820 ># Columns: 3 ># $ document  [3m [38;5;246m<int> [39m [23m 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18… ># $ topic     [3m [38;5;246m<int> [39m [23m 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ># $ gamma     [3m [38;5;246m<dbl> [39m [23m 0.001283143, 0.003547179, 0.003745510, 0.005495076, 0.0630417… ># Rows: 741,860 ># Columns: 3 ># $ topic  [3m [38;5;246m<int> [39m [23m 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1… ># $ term   [3m [38;5;246m<chr> [39m [23m \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\", \"#1\"… ># $ beta   [3m [38;5;246m<dbl> [39m [23m 1.874650e-112, 2.519509e-119, 1.248970e-118, 6.665355e-160, 3.21…"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"understanding-and-labeling-topics","dir":"Articles","previous_headings":"Analysing and interpreting the topic model","what":"Understanding and labeling topics","title":"Example: Topic modelling Covid preprints","text":"mentioned previously stm can use word probabilities also compute FREX (frequent exclusive) words per topic. can retrieved stm::labelTopics() function, returns ordered lists different word sets characterizing topic. can combine information high probability FREX words create word clouds topic, might help assign summary label topic. Word clouds showing 50 probable terms per topic. Words scaled normalized probability per topic, terms also among top 20 FREX terms highlighted orange. readability, terms ‘sars’, ‘cov’ ‘covid’ removed occur high probability topics. review combination FREX high probability terms distinct topics emerging, : “epidemic models” (Topic 1), “vaccines” (Topic 11), “testing” (Topic 16), “virus variants” (Topic 17), “treatments” (Topic 2), “mortality risks” (Topic 3), “mental health” (Topic 4), “country-wise case reports” (Topic 8), “virus molecular structure” (Topic 9). Deriving semantic labels also benefit review sample documents representative certain topics, .e. topic model assigns high topic proportion given topic document. Furthermore, consistency assigned semantic labels checked prior analysis (see example oolong package systematic approach).","code":"library(tidyr) library(tibble)  # get the top FREX words frex_top20 <- as.data.frame(labelTopics(covid_model_K20, n = 20)$frex) %>%   rownames_to_column(var = \"topic\") %>%   pivot_longer(starts_with(\"V\"), values_to = \"term\") %>%   mutate(is_frex = 1) %>%   select(-name)  topic_words <- tidytext::tidy(covid_model_K20, matrix = \"beta\") %>%   #filter(!(term %in% c(\"sars\", \"cov\", \"covid\"))) %>%    mutate(topic = as.character(topic)) %>%   group_by(topic) %>%   arrange(-beta) %>%   slice_head(n = 50) %>%   mutate(beta_norm = (beta - min(beta)) / (max(beta) - min(beta))) %>%   ungroup() %>%   left_join(frex_top20, by = c(\"topic\", \"term\")) %>%   mutate(is_frex = ifelse(is.na(is_frex), \"0\", \"1\")) %>%   filter(!(term %in% c(\"sars\", \"cov\", \"covid\"))) %>%   mutate(topic = paste(\"Topic\", topic))  ggplot(topic_words, aes(label = term, size = beta_norm, color = is_frex)) +   ggwordcloud::geom_text_wordcloud_area(shape = \"square\",                                         family = \"Arial\",                                         rm_outside = TRUE) +   scale_radius(range = c(4, 15)) +   scale_color_manual(values = c(\"0\" = \"black\", \"1\" = \"#D55E00\")) +    facet_wrap(~topic, ncol = 4)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"covariate-effects","dir":"Articles","previous_headings":"Analysing and interpreting the topic model","what":"Covariate effects","title":"Example: Topic modelling Covid preprints","text":"key feature STM incorporation document covariates topic model. example considered publication year preprint server covariates might influence prevalence topic document. also applied regression covariates fit model, extracted stm::estimateEffect(). first exploration can print regression tables selected topics. following sections illustrate exploration covariate effects several examples.","code":"summary(covid_effect_K20) >#  ># Call: ># estimateEffect(formula = 1:20 ~ server * s(year), stmobj = covid_model_K20,  >#     metadata = covid_stm_docs$meta) >#  >#  ># Topic 1: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.0234691  0.0037293   6.293 3.15e-10 *** ># servermedrxiv           0.1239232  0.0043586  28.432  < 2e-16 *** ># s(year)1               -0.0019149  0.0146887  -0.130    0.896     ># s(year)2               -0.0007865  0.0155647  -0.051    0.960     ># s(year)3                0.0083962  0.0067394   1.246    0.213     ># servermedrxiv:s(year)1 -0.0695105  0.0174071  -3.993 6.53e-05 *** ># servermedrxiv:s(year)2 -0.0965412  0.0191427  -5.043 4.60e-07 *** ># servermedrxiv:s(year)3 -0.0705269  0.0084723  -8.324  < 2e-16 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 2: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.098642   0.002878  34.275  < 2e-16 *** ># servermedrxiv          -0.085918   0.003145 -27.320  < 2e-16 *** ># s(year)1               -0.019903   0.011371  -1.750   0.0801 .   ># s(year)2               -0.011352   0.013433  -0.845   0.3980     ># s(year)3               -0.028609   0.004496  -6.364 2.00e-10 *** ># servermedrxiv:s(year)1  0.021566   0.012616   1.709   0.0874 .   ># servermedrxiv:s(year)2  0.008304   0.014448   0.575   0.5655     ># servermedrxiv:s(year)3  0.030388   0.005200   5.844 5.16e-09 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 3: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.011055   0.002792   3.959 7.54e-05 *** ># servermedrxiv           0.053966   0.003302  16.343  < 2e-16 *** ># s(year)1               -0.002378   0.011421  -0.208    0.835     ># s(year)2               -0.002153   0.011889  -0.181    0.856     ># s(year)3                0.001245   0.004840   0.257    0.797     ># servermedrxiv:s(year)1  0.014734   0.013861   1.063    0.288     ># servermedrxiv:s(year)2  0.014500   0.014987   0.968    0.333     ># servermedrxiv:s(year)3  0.029812   0.006523   4.570 4.89e-06 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 4: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.008872   0.003259   2.722  0.00648 **  ># servermedrxiv           0.057710   0.003838  15.037  < 2e-16 *** ># s(year)1                0.004666   0.013262   0.352  0.72495     ># s(year)2               -0.005152   0.013899  -0.371  0.71087     ># s(year)3                0.004496   0.005770   0.779  0.43581     ># servermedrxiv:s(year)1  0.020236   0.016341   1.238  0.21558     ># servermedrxiv:s(year)2 -0.003815   0.018020  -0.212  0.83233     ># servermedrxiv:s(year)3  0.020261   0.007663   2.644  0.00820 **  ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 5: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.0049192  0.0023197   2.121   0.0340 *   ># servermedrxiv           0.0543003  0.0027631  19.652   <2e-16 *** ># s(year)1               -0.0006750  0.0094505  -0.071   0.9431     ># s(year)2                0.0000698  0.0098912   0.007   0.9944     ># s(year)3                0.0011606  0.0040801   0.284   0.7761     ># servermedrxiv:s(year)1  0.0260079  0.0114508   2.271   0.0231 *   ># servermedrxiv:s(year)2 -0.0017523  0.0121705  -0.144   0.8855     ># servermedrxiv:s(year)3 -0.0086082  0.0053302  -1.615   0.1063     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 6: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.148599   0.003835  38.750  < 2e-16 *** ># servermedrxiv          -0.115773   0.004203 -27.543  < 2e-16 *** ># s(year)1               -0.020876   0.013403  -1.558   0.1193     ># s(year)2               -0.049456   0.012179  -4.061 4.91e-05 *** ># s(year)3               -0.043688   0.006021  -7.256 4.07e-13 *** ># servermedrxiv:s(year)1  0.005662   0.014976   0.378   0.7054     ># servermedrxiv:s(year)2  0.035675   0.013870   2.572   0.0101 *   ># servermedrxiv:s(year)3  0.030978   0.006943   4.462 8.15e-06 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 7: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.010711   0.002922   3.665 0.000248 *** ># servermedrxiv           0.086052   0.003482  24.717  < 2e-16 *** ># s(year)1               -0.004058   0.011530  -0.352 0.724874     ># s(year)2               -0.007870   0.012196  -0.645 0.518753     ># s(year)3               -0.003398   0.005174  -0.657 0.511353     ># servermedrxiv:s(year)1 -0.049387   0.014509  -3.404 0.000665 *** ># servermedrxiv:s(year)2 -0.019534   0.015749  -1.240 0.214882     ># servermedrxiv:s(year)3 -0.038443   0.006603  -5.822 5.87e-09 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 8: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.027236   0.003044   8.947  < 2e-16 *** ># servermedrxiv           0.108750   0.003552  30.620  < 2e-16 *** ># s(year)1               -0.012950   0.012244  -1.058 0.290210     ># s(year)2               -0.018329   0.012528  -1.463 0.143470     ># s(year)3               -0.017087   0.005166  -3.308 0.000941 *** ># servermedrxiv:s(year)1 -0.088443   0.014708  -6.013 1.84e-09 *** ># servermedrxiv:s(year)2 -0.046530   0.015530  -2.996 0.002736 **  ># servermedrxiv:s(year)3 -0.060316   0.006472  -9.320  < 2e-16 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 9: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.170526   0.004594  37.116  < 2e-16 *** ># servermedrxiv          -0.163969   0.004789 -34.241  < 2e-16 *** ># s(year)1                0.017942   0.019195   0.935 0.349949     ># s(year)2               -0.034733   0.020225  -1.717 0.085929 .   ># s(year)3               -0.028049   0.006611  -4.243 2.22e-05 *** ># servermedrxiv:s(year)1 -0.010865   0.020299  -0.535 0.592480     ># servermedrxiv:s(year)2  0.033047   0.022012   1.501 0.133273     ># servermedrxiv:s(year)3  0.027983   0.007195   3.889 0.000101 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 10: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             4.469e-02  3.321e-03  13.456  < 2e-16 *** ># servermedrxiv           1.178e-02  3.580e-03   3.292 0.000995 *** ># s(year)1                4.368e-03  1.457e-02   0.300 0.764279     ># s(year)2                9.783e-05  1.324e-02   0.007 0.994107     ># s(year)3                2.625e-02  5.819e-03   4.512 6.45e-06 *** ># servermedrxiv:s(year)1 -1.782e-02  1.631e-02  -1.093 0.274592     ># servermedrxiv:s(year)2 -3.029e-02  1.550e-02  -1.954 0.050762 .   ># servermedrxiv:s(year)3 -4.104e-02  6.953e-03  -5.903 3.61e-09 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 11: >#  ># Coefficients: >#                        Estimate Std. Error t value Pr(>|t|)     ># (Intercept)            0.005059   0.002337   2.164  0.03045 *   ># servermedrxiv          0.008197   0.002678   3.061  0.00221 **  ># s(year)1               0.010010   0.009824   1.019  0.30826     ># s(year)2               0.010071   0.010173   0.990  0.32219     ># s(year)3               0.006377   0.004235   1.506  0.13215     ># servermedrxiv:s(year)1 0.057135   0.011658   4.901 9.59e-07 *** ># servermedrxiv:s(year)2 0.073670   0.012535   5.877 4.22e-09 *** ># servermedrxiv:s(year)3 0.047081   0.005891   7.992 1.38e-15 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 12: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.022018   0.002839   7.754 9.16e-15 *** ># servermedrxiv           0.041909   0.003392  12.355  < 2e-16 *** ># s(year)1               -0.008498   0.011157  -0.762    0.446     ># s(year)2               -0.005969   0.012019  -0.497    0.619     ># s(year)3               -0.002627   0.004868  -0.540    0.589     ># servermedrxiv:s(year)1 -0.006806   0.013811  -0.493    0.622     ># servermedrxiv:s(year)2  0.009807   0.015772   0.622    0.534     ># servermedrxiv:s(year)3  0.034817   0.006496   5.360 8.40e-08 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 13: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.104427   0.003132  33.342  < 2e-16 *** ># servermedrxiv          -0.086419   0.003430 -25.194  < 2e-16 *** ># s(year)1               -0.031794   0.015481  -2.054   0.0400 *   ># s(year)2               -0.027938   0.015075  -1.853   0.0638 .   ># s(year)3               -0.023372   0.005596  -4.176 2.97e-05 *** ># servermedrxiv:s(year)1  0.078032   0.017901   4.359 1.31e-05 *** ># servermedrxiv:s(year)2  0.028257   0.016832   1.679   0.0932 .   ># servermedrxiv:s(year)3  0.041179   0.006610   6.230 4.73e-10 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 14: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.124605   0.003436  36.265   <2e-16 *** ># servermedrxiv          -0.112717   0.003647 -30.905   <2e-16 *** ># s(year)1                0.004229   0.015115   0.280    0.780     ># s(year)2               -0.007597   0.015678  -0.485    0.628     ># s(year)3                0.007565   0.006338   1.194    0.233     ># servermedrxiv:s(year)1 -0.003168   0.016076  -0.197    0.844     ># servermedrxiv:s(year)2  0.005315   0.016764   0.317    0.751     ># servermedrxiv:s(year)3 -0.005093   0.007108  -0.716    0.474     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 15: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.053471   0.003518  15.198  < 2e-16 *** ># servermedrxiv          -0.027392   0.003960  -6.918 4.67e-12 *** ># s(year)1                0.044476   0.014694   3.027  0.00247 **  ># s(year)2                0.024935   0.015489   1.610  0.10744     ># s(year)3                0.017760   0.006472   2.744  0.00607 **  ># servermedrxiv:s(year)1  0.003782   0.017196   0.220  0.82590     ># servermedrxiv:s(year)2  0.033595   0.017825   1.885  0.05947 .   ># servermedrxiv:s(year)3 -0.003476   0.007614  -0.457  0.64800     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 16: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.0531213  0.0034877  15.231  < 2e-16 *** ># servermedrxiv           0.0176751  0.0040771   4.335 1.46e-05 *** ># s(year)1               -0.0494702  0.0129480  -3.821 0.000133 *** ># s(year)2               -0.0293926  0.0132136  -2.224 0.026128 *   ># s(year)3               -0.0278605  0.0057381  -4.855 1.21e-06 *** ># servermedrxiv:s(year)1  0.0608404  0.0149205   4.078 4.56e-05 *** ># servermedrxiv:s(year)2  0.0011648  0.0159610   0.073 0.941825     ># servermedrxiv:s(year)3 -0.0008017  0.0071704  -0.112 0.910975     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 17: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.012519   0.002370   5.282 1.28e-07 *** ># servermedrxiv          -0.010869   0.002665  -4.079 4.53e-05 *** ># s(year)1                0.062511   0.011921   5.244 1.59e-07 *** ># s(year)2                0.167316   0.015985  10.467  < 2e-16 *** ># s(year)3                0.074776   0.005290  14.135  < 2e-16 *** ># servermedrxiv:s(year)1 -0.043591   0.013333  -3.269  0.00108 **  ># servermedrxiv:s(year)2 -0.080265   0.017897  -4.485 7.33e-06 *** ># servermedrxiv:s(year)3 -0.037928   0.006115  -6.202 5.64e-10 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 18: >#  ># Coefficients: >#                         Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.055674   0.003040  18.314  < 2e-16 *** ># servermedrxiv          -0.019901   0.003482  -5.716 1.10e-08 *** ># s(year)1                0.005535   0.012054   0.459  0.64610     ># s(year)2                0.004271   0.012663   0.337  0.73589     ># s(year)3                0.029381   0.005781   5.082 3.75e-07 *** ># servermedrxiv:s(year)1 -0.004425   0.014581  -0.303  0.76155     ># servermedrxiv:s(year)2 -0.004803   0.015323  -0.313  0.75396     ># servermedrxiv:s(year)3 -0.020632   0.006909  -2.986  0.00283 **  ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 19: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.0135353  0.0025914   5.223 1.77e-07 *** ># servermedrxiv           0.0273595  0.0030323   9.023  < 2e-16 *** ># s(year)1                0.0006214  0.0099419   0.062   0.9502     ># s(year)2               -0.0063981  0.0105220  -0.608   0.5431     ># s(year)3               -0.0030789  0.0043889  -0.702   0.4830     ># servermedrxiv:s(year)1 -0.0032134  0.0122771  -0.262   0.7935     ># servermedrxiv:s(year)2  0.0283211  0.0132724   2.134   0.0329 *   ># servermedrxiv:s(year)3  0.0027228  0.0057558   0.473   0.6362     ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 20: >#  ># Coefficients: >#                          Estimate Std. Error t value Pr(>|t|)     ># (Intercept)             0.0067418  0.0019448   3.467 0.000528 *** ># servermedrxiv           0.0314339  0.0022246  14.130  < 2e-16 *** ># s(year)1               -0.0014566  0.0076779  -0.190 0.849535     ># s(year)2               -0.0001042  0.0082192  -0.013 0.989882     ># s(year)3                0.0004272  0.0034184   0.125 0.900548     ># servermedrxiv:s(year)1  0.0086405  0.0096028   0.900 0.368241     ># servermedrxiv:s(year)2  0.0128936  0.0106979   1.205 0.228117     ># servermedrxiv:s(year)3  0.0213483  0.0046536   4.588  4.5e-06 *** ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"publication-year","dir":"Articles","previous_headings":"Analysing and interpreting the topic model > Covariate effects","what":"Publication year","title":"Example: Topic modelling Covid preprints","text":"stm offers several built-methods explore covariate effects visually. visualization effect preprint publication year expected topic proportions confirm trends appear match intuitively different phases Covid-19 pandemic. Modelling spread infections (Topic 1) high relevance initially, declined later, applies (PCR-)testing (Topic 16), vaccines (Topic 11) received limited coverage earlier preprints, became important later years developed distributed.  Alternatively, stminsights package used extract regression information stm effects object create customized charts.","code":"plot(covid_effect_K20,      covariate = \"year\",      method = \"continuous\",      model = covid_model_K20,      topics = c(1, 16, 11),      xaxt = \"n\",      main = 'Effect of publication year on prevalence of Topic 1 (\"epidemic \\nmodels\"), Topic 16 (\"testing\") and Topic 11 (\"vaccines\")',      labeltype = \"prob\",      xlab = \"Publication year\") axis(1, at = c(\"2020\",\"2021\",\"2022\",\"2023\"), labels = c(2020, 2021, 2022, 2023)) library(stminsights)  year_effect <- get_effects(estimates = covid_effect_K20,                             variable = \"year\",                            type = \"continuous\")  year_effect %>%   mutate(topic = as.character(topic)) %>%   mutate(topic = paste(\"Topic\", topic)) %>%     ggplot(aes(x = value, y = proportion)) +       geom_line() +       geom_ribbon(aes(ymin = lower, ymax = upper),                    alpha = 0.2, linetype = 0)  +       xlab(\"Publication year\") +       ylab(\"Topic prevalence\") +       facet_wrap(~topic, ncol = 4) +       theme_minimal()"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"preprint-server","dir":"Articles","previous_headings":"Analysing and interpreting the topic model > Covariate effects","what":"Preprint server","title":"Example: Topic modelling Covid preprints","text":"model also incorporated preprint server (bioRxiv medRxiv) covariate. hypothesized prevalence certain topics influenced covariate, .e. likely see certain topics either bioRxiv medRxiv. STM interprets treatment (see (Roberts et al. 2014) background examples) can extract effect treatment regression object returned estimateEffect(). stm::plot() offers different methods explore effects. figure lists effect ‘treatment medrxiv’ topics model. treatment can positive negative effect. can example see Topic 4 (“mental health”) can expected higher prevalence medRxiv preprints, whereas Topic 9 (“virus molecular structure”) much lower prevalence medRxiv preprints, .e. expected higher prevalence bioRxiv preprints.  can also compare topical prevalence effect covariate values single topic. figure confirms previous observation Topic 9 (“virus molecular structure”) prevalence close zero medRxiv preprints prevalence approximately 0.17 bioRxiv preprints, .e. seems appear almost exclusively latter.","code":"plot(covid_effect_K20,       covariate = \"server\",      #topics = c(9, 10, 16, 1),      model = covid_model_K20,       method = \"difference\",      cov.value1 = \"medrxiv\", cov.value2 = \"biorxiv\",      xlab = \"higher biorxiv prevalence ... higher medrxiv prevalence\",      xlim = c(-0.19, 0.1),      #labeltype = \"prob\",      main = \"Effect of preprint server ('treatment medrxiv')\") plot(covid_effect_K20,       covariate = \"server\",      topics = c(9),      model = covid_model_K20,        method = \"pointestimate\",      xlab = \"Topical prevalence\",      xlim = c(-0.04, 0.2),      #labeltype = \"prob\",      main = \"Effect of preprint server covariate for Topic 9\")"},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"combination-of-preprint-server-and-publication-year","dir":"Articles","previous_headings":"Analysing and interpreting the topic model > Covariate effects","what":"Combination of preprint server and publication year","title":"Example: Topic modelling Covid preprints","text":"Finally, can also explore combined effect covariates; assumed interacting effect two covariates server year. plot visualizes Topic 17 (“virus variants”) illustrates topical prevalence increased throughout pandemic preprints topic apparently received coverage bioRxiv preprints.  , stminsights can used retrieve information create customized visualizations combined covariate effect.","code":"biorxiv_effect <- get_effects(covid_effect_K20,                               variable = \"year\", type = \"continuous\",                                moderator = \"server\", modval = \"biorxiv\")  medrxiv_effect <- get_effects(covid_effect_K20,                               variable = \"year\", type = \"continuous\",                                moderator = \"server\", modval = \"medrxiv\")  server_effects <- bind_rows(biorxiv_effect, medrxiv_effect)  server_effects %>%   mutate(topic = as.character(topic)) %>%   mutate(topic = paste(\"Topic\", topic)) %>%     ggplot(aes(x = value, y = proportion, color = moderator,                group = moderator, fill = moderator)) +       geom_line() +       geom_ribbon(aes(ymin = lower, ymax = upper,                        fill = moderator), alpha = 0.2, linetype = 0) +       xlab(\"Publication year\") +       ylab(\"Topic prevalence\") +       facet_wrap(~topic, ncol = 4) +       theme_minimal() +       theme(legend.position = \"bottom\")"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/covid-preprint-topics.html","id":"topic-correlations","dir":"Articles","previous_headings":"Analysing and interpreting the topic model > Exploring the topic structure","what":"Topic correlations","title":"Example: Topic modelling Covid preprints","text":"Finally, considering STM extending (Roberts, Stewart, Tingley 2019) correlated topic model (Blei Lafferty 2007) may also explore topics frequently cooccuring. topic correlation matrix retrieved stm::topicCorr() can plotted. resulting figure indicates least two clusters topics.  correlation matrix can used analysis (e.g. networks clusters) alternative visualizations. outside scope example course module. illustration, following figure creates alternative network visualization, nodes colored according community analysis topical network, reveals four distinct topical clusters.","code":"covid_topic_correlations <- topicCorr(covid_model_K20)  plot(covid_topic_correlations)"},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"getting-the-document-data","dir":"Articles","previous_headings":"Exercise tasks","what":"Getting the document data","title":"Exercise 1: Topic modeling biodiversity preprints","text":"assume created local copy preprint data run analysis (see information code samples “Getting document data” vignette(\"covid-preprint-topics\")).","code":"load(url(\"PREPRINT_RDATA_LOCATION_HERE\"))"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"cleaning-filtering-and-annotating-the-data","dir":"Articles","previous_headings":"Exercise tasks","what":"Cleaning, filtering and annotating the data","title":"Exercise 1: Topic modeling biodiversity preprints","text":"example planning explore whether publication status influences topic prevalence. therefore adapt time range consider preprints added 2017 2021. reduce subset preprints reference term ‘biodiversity’ either preprint title abstract.","code":"# adapt based on the covid preprints example"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"create-a-corpus","dir":"Articles","previous_headings":"Exercise tasks > Preparing and preprocessing the documents for text analysis","what":"Create a corpus","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Create corpus explore properties.","code":"# quanteda is used for corpus creation"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"tokenize-and-preprocess","dir":"Articles","previous_headings":"Exercise tasks > Preparing and preprocessing the documents for text analysis","what":"Tokenize and preprocess","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Tokenize applying steps Covid preprint example.","code":"# quanteda is used for tokenization"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"create-a-document-feature-matrix","dir":"Articles","previous_headings":"Exercise tasks > Preparing and preprocessing the documents for text analysis","what":"Create a Document-feature matrix","title":"Exercise 1: Topic modeling biodiversity preprints","text":"","code":"# quanteda is used for creation of a DFM"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"filter-terms-and-documents","dir":"Articles","previous_headings":"Exercise tasks > Preparing and preprocessing the documents for text analysis","what":"Filter terms and documents","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Remove stopwords document-feature-matrix. Explore properties. Filter tokens documents applying approach Covid preprint example.","code":"# quanteda is used for stopword removal # quanteda is used for filtering"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"fitting-the-stm-topic-model","dir":"Articles","previous_headings":"Exercise tasks > Topic modeling","what":"Fitting the STM topic model","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Fit stm topic model 10 topics prepared data. model consider interacting effect covariates is_published publication year topical prevalence. Apply seed argument value 9868467.","code":"# convert the DFM into stm format and run the stm() function"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"estimating-the-effect-of-document-covariates","dir":"Articles","previous_headings":"Exercise tasks > Topic modeling","what":"Estimating the effect of document covariates","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Evaluate effect previously chosen topic prevalence covariates topics. concludes fitting model. following sections step sample exploration topic model.","code":"# estimateEffect() on the topic model"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"basic-topic-model-information","dir":"Articles","previous_headings":"Exercise tasks > Analysing and interpreting the topic model","what":"Basic topic model information","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Plot model summary 7 frequent words per topic. Print summary() topic model explore sets words characterize 10 topics.","code":"# stm plot() teh topic model provides a summary of topic proportions # print a summary() of the topic model"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"understanding-and-labeling-topics","dir":"Articles","previous_headings":"Exercise tasks","what":"Understanding and labeling topics","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Create word clouds 10 topics using 30 words highest probability per topic. Remove term “biodiversity” display.","code":"# word clouds are a useful first step to arrive at summary labels for topics"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"covariate-effects","dir":"Articles","previous_headings":"Exercise tasks","what":"Covariate effects","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Print regression tables selected topics.","code":"# print a summary() of effects"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"publication-year","dir":"Articles","previous_headings":"Exercise tasks > Covariate effects","what":"Publication year","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Use stm plot method create plot shows effect publication year topical prevalence Topic 4 Topic 8. Annotate probable terms. Alternatively, stminsights package used extract regression information stm effects object create customized charts.","code":"# stm plot offers various different plot options for covariate effects # stminsights allows to get effects in a format suitable for ggplot2"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"publication-status-effect","dir":"Articles","previous_headings":"Exercise tasks > Covariate effects","what":"Publication status effect","title":"Exercise 1: Topic modeling biodiversity preprints","text":"also incoporated publication status model (covariate is_published). Using stm plot method explore effect treatment “published” topical prevalence. Compare topical prevalence effect covariate is_published Topic 4.","code":"# stm plot offers various different plotoptions for covariate effects # stm plot offers various different plotoptions for covariate effects"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"combination-of-publication-status-and-publication-year","dir":"Articles","previous_headings":"Exercise tasks > Covariate effects","what":"Combination of publication status and publication year","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Finally, can also explore combined effect covariates; assumed interacting effect two covariates is_published year. Using stm plot function explore combined interacting covariate effect Topic 4. , stminsights can used retrieve information create customized visualizations combined covariate effect.","code":"# stminsights allows to get effects in a format suitable for ggplot2"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"topic-correlations","dir":"Articles","previous_headings":"Exercise tasks > Exploring the topic structure","what":"Topic correlations","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Finally, retrieve topic correlations matrix plot cooccurrence network.","code":"# topic correlations retrieved with stm"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"getting-the-document-data-1","dir":"Articles","previous_headings":"Solution","what":"Getting the document data","title":"Exercise 1: Topic modeling biodiversity preprints","text":"assume created local copy preprint data run analysis (see information code samples “Getting document data” vignette(\"covid-preprint-topics\")).","code":"load(url(\"PREPRINT_RDATA_LOCATION_HERE\"))"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"cleaning-filtering-and-annotating-the-data-1","dir":"Articles","previous_headings":"Solution","what":"Cleaning, filtering and annotating the data","title":"Exercise 1: Topic modeling biodiversity preprints","text":"example planning explore whether publication status influences topic prevalence. therefore adapt time range consider preprints added 2017 2021. reduce subset preprints reference term ‘biodiversity’ either preprint title abstract.","code":"library(dplyr) library(stringr)  preprints_cleaned <- preprints_raw %>%   group_by(doi) %>%   filter(version == max(version)) %>%   ungroup() %>%   distinct(doi, .keep_all = TRUE)  preprints <- preprints_cleaned %>%   mutate(published = stringr::str_trim(published)) %>%   mutate(published = na_if(published, \"NA\")) %>%   mutate(is_published = as.numeric(!is.na(published))) %>%   mutate(is_published = case_when(is_published == 1 ~ \"published\",                                   is_published == 0 ~ \"not published\",                                   TRUE ~ \"undefined\")) %>%   mutate(year = lubridate::year(date)) %>%   filter(year >= 2017 & year <= 2021) %>%    select(doi, server, title, abstract, date, year, version, is_published)  keywords <- c(\"biodiversity\")  search_pattern <- stringr::regex(paste(keywords, collapse = \"|\"),                                   ignore_case = TRUE)  biodiv_preprints <- preprints %>%   filter(stringr::str_detect(title, pattern = search_pattern) |            stringr::str_detect(abstract, pattern = search_pattern))"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"create-a-corpus-1","dir":"Articles","previous_headings":"Solution > Preparing and preprocessing the documents for text analysis","what":"Create a corpus","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Create corpus explore properties.","code":"library(quanteda)  pubs_corpus <- biodiv_preprints %>%   quanteda::corpus(docid_field = \"doi\", text_field = \"abstract\")  # pubs_corpus # Corpus consisting of 29,692 documents and 6 docvars."},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"tokenize-and-preprocess-1","dir":"Articles","previous_headings":"Solution > Preparing and preprocessing the documents for text analysis","what":"Tokenize and preprocess","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Tokenize applying steps Covid preprint example.","code":"pubs_tokens <- pubs_corpus %>%   quanteda::tokens(remove_punct = TRUE,                    remove_symbols = TRUE,                    remove_numbers = TRUE,                    remove_url = TRUE,                    remove_separators = TRUE,                    split_hyphens = TRUE)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"create-a-document-feature-matrix-1","dir":"Articles","previous_headings":"Solution > Preparing and preprocessing the documents for text analysis","what":"Create a Document-feature matrix","title":"Exercise 1: Topic modeling biodiversity preprints","text":"","code":"pubs_dfm <- pubs_tokens %>%   quanteda::dfm()"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"filter-terms-and-documents-1","dir":"Articles","previous_headings":"Solution > Preparing and preprocessing the documents for text analysis","what":"Filter terms and documents","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Remove stopwords document-feature-matrix. Explore properties. Filter tokens documents applying approach Covid preprint example.","code":"pubs_dfm <- pubs_dfm %>%   quanteda::dfm_remove(pattern = quanteda::stopwords(\"english\")) #%>%   #quanteda::dfm_wordstem() pubs_dfm <- pubs_dfm %>%   quanteda::dfm_remove(min_nchar = 2) %>%   quanteda::dfm_trim(min_docfreq = 2, docfreq_type = \"count\") %>%   quanteda::dfm_subset(quanteda::ntoken(.) > 4)"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"fitting-the-stm-topic-model-1","dir":"Articles","previous_headings":"Solution > Topic modeling","what":"Fitting the STM topic model","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Fit stm topic model 10 topics prepared data. model consider interacting effect covariates is_published publication year topical prevalence. Apply seed argument value 9868467.","code":"library(stm)  biodiv_stm_docs <- quanteda::convert(pubs_dfm, to = \"stm\")  biodiv_model_K10 <- stm(documents = biodiv_stm_docs$documents,                     vocab = biodiv_stm_docs$vocab,                     data = biodiv_stm_docs$meta,                     prevalence = ~ is_published * year,                     K = 10,                     verbose = TRUE,                     seed = seed_stm)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"estimating-the-effect-of-document-covariates-1","dir":"Articles","previous_headings":"Solution > Topic modeling","what":"Estimating the effect of document covariates","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Evaluate effect previously chosen topic prevalence covariates topics. concludes fitting model. following sections step sample exploration topic model.","code":"biodiv_effect_K10 <- estimateEffect(1:10 ~ is_published * year,                                    stmobj = biodiv_model_K10,                                    metadata = biodiv_stm_docs$meta)"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"basic-topic-model-information-1","dir":"Articles","previous_headings":"Solution > Analysing and interpreting the topic model","what":"Basic topic model information","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Plot model summary 7 frequent words per topic.  Print summary() topic model explore sets words characterize 10 topics.","code":"plot(biodiv_model_K10, n = 7) summary(biodiv_model_K10) ># A topic model with 10 topics, 1495 documents and a 8838 word dictionary. ># Topic 1 Top Words: >#       Highest Prob: species, fish, marine, invasive, biodiversity, native, river  >#       FREX: coral, reefs, lakes, fisheries, reef, fishing, ocean  >#       Lift: advection, afdw, aggregations, aleutian, ampat, amphipods, andaman  >#       Score: fish, reef, islands, coral, fisheries, fishing, sea  ># Topic 2 Top Words: >#       Highest Prob: data, species, biodiversity, can, information, using, research  >#       FREX: user, users, automated, learning, databases, images, algorithms  >#       Lift: cheilostome, cnns, crux, digitized, disparities, dnn, echolocating  >#       Score: images, users, user, algorithms, pipeline, learning, students  ># Topic 3 Top Words: >#       Highest Prob: host, disease, biodiversity, populations, microbiota, human, infection  >#       FREX: infection, pathogen, virus, viruses, viral, diseases, infections  >#       Lift: antimicrobial, antimicrobials, attack, auxiliary, baits, brain, brood  >#       Score: infection, disease, host, pathogen, gut, microbiota, virus  ># Topic 4 Top Words: >#       Highest Prob: genetic, species, genome, populations, gene, population, genes  >#       FREX: snp, alleles, introgression, genome, genomic, genetic, genomes  >#       Lift: 3a, admixed, angustifolia, antibacterial, aureus, beak, beast  >#       Score: genome, genetic, genes, genomes, genomic, gene, speciation  ># Topic 5 Top Words: >#       Highest Prob: species, model, biodiversity, can, ecological, models, dynamics  >#       FREX: coexistence, competitive, theory, simulations, competition, stability, empirical  >#       Lift: abandon, absences, accumulates, aggressively, anchovy, archosaurs, assumes  >#       Score: competitive, theory, coexistence, competition, stability, simulations, preemption  ># Topic 6 Top Words: >#       Highest Prob: species, diversity, biodiversity, change, richness, climate, across  >#       FREX: climatic, gradients, biotic, turnover, climate, scales, richness  >#       Lift: arabia, bioregions, bryophyte, constantly, divide, endotherms, equivalence  >#       Score: richness, climate, elevational, phylogenetic, zeta, ldg, gradients  ># Topic 7 Top Words: >#       Highest Prob: plant, soil, diversity, communities, microbial, community, species  >#       FREX: mixtures, fire, soil, aboveground, amf, nitrogen, plant  >#       Lift: biodiv, conditioned, decomposer, exudate, fertilisation, microclimate, microsite  >#       Score: soil, microbial, grazing, bacterial, amf, mixtures, crop  ># Topic 8 Top Words: >#       Highest Prob: forest, forests, species, tree, cover, de, biodiversity  >#       FREX: forest, forests, en, de, plantations, la, es  >#       Lift: como, diversidad, landcover, que, una, vegetable, acacia  >#       Score: forest, forests, la, que, de, las, plantations  ># Topic 9 Top Words: >#       Highest Prob: conservation, species, biodiversity, areas, land, use, management  >#       FREX: iucn, socio, protected, lands, pas, conservation, nations  >#       Lift: eu, herpetofauna, pas, 30x30, abroad, accessing, achievements  >#       Score: protected, land, pas, iucn, lands, natura, conservation  ># Topic 10 Top Words: >#       Highest Prob: dna, edna, samples, species, metabarcoding, biodiversity, diversity  >#       FREX: edna, metabarcoding, samples, dna, primer, coi, biomonitoring  >#       Lift: 1the, acuta, asv, battery, benthos, bony, bruv  >#       Score: edna, metabarcoding, dna, samples, primer, coi, cristatus"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"understanding-and-labeling-topics-1","dir":"Articles","previous_headings":"Solution","what":"Understanding and labeling topics","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Create word clouds 10 topics using 30 words highest probability per topic. Remove term “biodiversity” display. Word clouds showing 30 probable terms per topic.","code":"library(tidyr) library(tibble)  # get the top FREX words frex_top20 <- as.data.frame(labelTopics(biodiv_model_K10, n = 25)$frex) %>%   rownames_to_column(var = \"topic\") %>%   pivot_longer(starts_with(\"V\"), values_to = \"term\") %>%   mutate(is_frex = 1) %>%   select(-name)  topic_words <- tidytext::tidy(biodiv_model_K10, matrix = \"beta\") %>%   #filter(!(term %in% c(\"sars\", \"cov\", \"covid\"))) %>%    mutate(topic = as.character(topic)) %>%   group_by(topic) %>%   arrange(-beta) %>%   slice_head(n = 30) %>%   mutate(beta_norm = (beta - min(beta)) / (max(beta) - min(beta))) %>%   ungroup() %>%   left_join(frex_top20, by = c(\"topic\", \"term\")) %>%   mutate(is_frex = ifelse(is.na(is_frex), \"0\", \"1\")) %>%   filter(!(term %in% c(\"biodiversity\"))) %>%   mutate(topic = paste(\"Topic\", topic))  ggplot(topic_words, aes(label = term, size = beta_norm, color = is_frex)) +   ggwordcloud::geom_text_wordcloud_area(shape = \"square\",                                         family = \"Arial\",                                         rm_outside = TRUE) +   scale_radius(range = c(4, 15)) +   scale_color_manual(values = c(\"0\" = \"black\", \"1\" = \"#D55E00\")) +    facet_wrap(~topic, ncol = 5)"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"covariate-effects-1","dir":"Articles","previous_headings":"Solution","what":"Covariate effects","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Print regression tables selected topics.","code":"summary(biodiv_effect_K10) >#  ># Call: ># estimateEffect(formula = 1:10 ~ is_published * year, stmobj = biodiv_model_K10,  >#     metadata = biodiv_stm_docs$meta) >#  >#  ># Topic 1: >#  ># Coefficients: >#                             Estimate Std. Error t value Pr(>|t|) ># (Intercept)                -2.034609  15.151575  -0.134    0.893 ># is_publishedpublished      -6.800020  19.604496  -0.347    0.729 ># year                        0.001049   0.007502   0.140    0.889 ># is_publishedpublished:year  0.003363   0.009707   0.346    0.729 >#  >#  ># Topic 2: >#  ># Coefficients: >#                             Estimate Std. Error t value Pr(>|t|) ># (Intercept)                -6.248388  17.847374  -0.350    0.726 ># is_publishedpublished       5.120831  23.532046   0.218    0.828 ># year                        0.003147   0.008837   0.356    0.722 ># is_publishedpublished:year -0.002541   0.011651  -0.218    0.827 >#  >#  ># Topic 3: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                -1.9200319 17.9940858  -0.107    0.915 ># is_publishedpublished      -2.2388880 22.7147666  -0.099    0.921 ># year                        0.0009848  0.0089093   0.111    0.912 ># is_publishedpublished:year  0.0011151  0.0112468   0.099    0.921 >#  >#  ># Topic 4: >#  ># Coefficients: >#                             Estimate Std. Error t value Pr(>|t|) ># (Intercept)                 9.931711  19.364376   0.513    0.608 ># is_publishedpublished      12.351156  23.740488   0.520    0.603 ># year                       -0.004875   0.009587  -0.508    0.611 ># is_publishedpublished:year -0.006099   0.011755  -0.519    0.604 >#  >#  ># Topic 5: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                 24.414252  18.421168   1.325    0.185 ># is_publishedpublished      -10.554890  23.324222  -0.453    0.651 ># year                        -0.012029   0.009121  -1.319    0.187 ># is_publishedpublished:year   0.005220   0.011549   0.452    0.651 >#  >#  ># Topic 6: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                13.8814856 17.3257892   0.801    0.423 ># is_publishedpublished       0.6004826 22.1206064   0.027    0.978 ># year                       -0.0068061  0.0085785  -0.793    0.428 ># is_publishedpublished:year -0.0003012  0.0109529  -0.028    0.978 >#  >#  ># Topic 7: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                -18.098871  18.608112  -0.973    0.331 ># is_publishedpublished       14.448709  23.046982   0.627    0.531 ># year                         0.009016   0.009214   0.979    0.328 ># is_publishedpublished:year  -0.007154   0.011412  -0.627    0.531 >#  >#  ># Topic 8: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|) ># (Intercept)                  6.658318  12.677144   0.525    0.600 ># is_publishedpublished      -12.182443  15.957518  -0.763    0.445 ># year                        -0.003265   0.006277  -0.520    0.603 ># is_publishedpublished:year   0.006027   0.007901   0.763    0.446 >#  >#  ># Topic 9: >#  ># Coefficients: >#                              Estimate Std. Error t value Pr(>|t|)   ># (Intercept)                -32.535651  19.312652  -1.685   0.0923 . ># is_publishedpublished       10.169158  25.243083   0.403   0.6871   ># year                         0.016182   0.009562   1.692   0.0908 . ># is_publishedpublished:year  -0.005046   0.012499  -0.404   0.6865   ># --- ># Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 >#  >#  ># Topic 10: >#  ># Coefficients: >#                             Estimate Std. Error t value Pr(>|t|) ># (Intercept)                 5.610703  18.229707   0.308    0.758 ># is_publishedpublished      -9.292909  21.733179  -0.428    0.669 ># year                       -0.002740   0.009026  -0.304    0.762 ># is_publishedpublished:year  0.004613   0.010761   0.429    0.668"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"publication-year-1","dir":"Articles","previous_headings":"Solution > Covariate effects","what":"Publication year","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Use stm plot method create plot shows effect publication year topical prevalence Topic 4 Topic 8. Annotate probable terms.  Alternatively, stminsights package used extract regression information stm effects object create customized charts.","code":"plot(biodiv_effect_K10,      covariate = \"year\",      method = \"continuous\",      model = biodiv_model_K10,      topics = c(4, 8),      xaxt = \"n\",      main = 'Effect of publication year on prevalence of Topic 4 (\"???\") and Topic 8 (\"???\")',      labeltype = \"prob\",      xlab = \"Publication year\") axis(1, at = c(\"2017\",\"2018\",\"2019\",\"2020\", \"2021\"), labels = c(2017, 2018, 2019, 2020, 2021)) library(stminsights)  year_effect <- get_effects(estimates = biodiv_effect_K10,                             variable = \"year\",                            type = \"continuous\")  year_effect %>%   mutate(topic = as.character(topic)) %>%   mutate(topic = paste(\"Topic\", topic)) %>%     ggplot(aes(x = value, y = proportion)) +       geom_line() +       geom_ribbon(aes(ymin = lower, ymax = upper),                    alpha = 0.2, linetype = 0)  +       xlab(\"Publication year\") +       ylab(\"Topic prevalence\") +       facet_wrap(~topic, ncol = 5) +       theme_minimal()"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"publication-status-effect-1","dir":"Articles","previous_headings":"Solution > Covariate effects","what":"Publication status effect","title":"Exercise 1: Topic modeling biodiversity preprints","text":"also incoporated publication status model (covariate is_published). Using stm plot method explore effect treatment “published” topical prevalence.  Compare topical prevalence effect covariate is_published Topic 4.","code":"plot(biodiv_effect_K10,       covariate = \"is_published\",      #topics = c(9, 10, 16, 1),      model = biodiv_model_K10,       method = \"difference\",      cov.value1 = \"published\", cov.value2 = \"not published\",      xlab = \"higher prevalence in unpublished ... higher prevalence in published\",      #xlim = c(-0.19, 0.1),      #labeltype = \"prob\",      main = \"Effect of preprint server (treatment 'published')\") plot(biodiv_effect_K10,       covariate = \"is_published\",      topics = c(4),      model = biodiv_model_K10,        method = \"pointestimate\",      xlab = \"Topical prevalence\",      #xlim = c(-0.04, 0.2),      #labeltype = \"prob\",      main = \"Effect of preprint 'is_published' covariate for Topic 4\")"},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"combination-of-publication-status-and-publication-year-1","dir":"Articles","previous_headings":"Solution > Covariate effects","what":"Combination of publication status and publication year","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Finally, can also explore combined effect covariates; assumed interacting effect two covariates is_published year. Using stm plot function explore combined interacting covariate effect Topic 4.  , stminsights can used retrieve information create customized visualizations combined covariate effect.","code":"published_effect <- get_effects(biodiv_effect_K10,                                  variable = \"year\", type = \"continuous\",                                  moderator = \"is_published\", modval = \"published\")  unpublished_effect <- get_effects(biodiv_effect_K10,                                   variable = \"year\", type = \"continuous\",                                    moderator = \"is_published\", modval = \"not published\")  is_published_effects <- bind_rows(published_effect, unpublished_effect)  is_published_effects %>%   mutate(topic = as.character(topic)) %>%   mutate(topic = paste(\"Topic\", topic)) %>%     ggplot(aes(x = value, y = proportion, color = moderator,                group = moderator, fill = moderator)) +       geom_line() +       geom_ribbon(aes(ymin = lower, ymax = upper,                        fill = moderator), alpha = 0.2, linetype = 0) +       xlab(\"Publication year\") +       ylab(\"Topic prevalence\") +       facet_wrap(~topic, ncol = 5) +       theme_minimal() +       theme(legend.position = \"bottom\")"},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/articles/exercise1-biodiv.html","id":"topic-correlations-1","dir":"Articles","previous_headings":"Solution > Exploring the topic structure","what":"Topic correlations","title":"Exercise 1: Topic modeling biodiversity preprints","text":"Finally, retrieve topic correlations matrix plot cooccurrence network.","code":"covid_topic_correlations <- topicCorr(biodiv_model_K10, cutoff = 0.001)  plot(covid_topic_correlations)"},{"path":"https://sdaume.github.io/srcquantcourse/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Stefan Daume. Author, maintainer.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Daume S (2024). srcquantcourse: Scripts Exercises SRC Quantitative Methods PhD Course. R package version 0.0.0.9000, https://github.com/sdaume/srcquantcourse, https://sdaume.github.io/srcquantcourse.","code":"@Manual{,   title = {srcquantcourse: Scripts and Exercises for the SRC Quantitative Methods PhD Course},   author = {Stefan Daume},   year = {2024},   note = {R package version 0.0.0.9000, https://github.com/sdaume/srcquantcourse},   url = {https://sdaume.github.io/srcquantcourse}, }"},{"path":"https://sdaume.github.io/srcquantcourse/index.html","id":"srcquantcourse","dir":"","previous_headings":"","what":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","title":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","text":"goal srcquantcourse provide sample analysis, replication scripts exercises data analysis module SRC Quantitative Methods PhD Course; part module concentrates probabilistic topic modelling.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","text":"can install development version srcquantcourse GitHub : Alternatively, clone repo (https://github.com/sdaume/srcquantcourse) order work modify scripts.","code":"# install.packages(\"devtools\") devtools::install_github(\"sdaume/srcquantcourse\")"},{"path":"https://sdaume.github.io/srcquantcourse/index.html","id":"license-credits-and-acknowledgements","dir":"","previous_headings":"","what":"License, credits and acknowledgements","title":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","text":"package shared MIT License. package relies several R packages listed package DESCRIPTION accompanying scripts. work packages’ authors hereby gratefully acknowledged. illustrate methods covered package preprint meta-data bioRxiv medRxiv used. preprint servers provide API access preprints explicitly intended support text mining; hereby gratefully acknowledged. actual preprints shared package, scripts utilizing medrxivr package provided obtain preprint data replicate results. package developed support education research Stockholm Resilience Centre; research benefited funding Swedish Research Council Sustainable Development (Formas).","code":""},{"path":"https://sdaume.github.io/srcquantcourse/index.html","id":"disclaimer","dir":"","previous_headings":"","what":"Disclaimer","title":"Scripts and Exercises for the SRC Quantitative Methods PhD Course","text":"package author(s) associated bioRxiv medRxiv. package developed reusable tool education author(s) research comes guarantee correctness results included package functions.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_effect_K10.html","id":null,"dir":"Reference","previous_headings":"","what":"An STM regression object for a topic model with 10 topics — biodiv_effect_K10","title":"An STM regression object for a topic model with 10 topics — biodiv_effect_K10","text":"package data set provides results applying stm::estimateEffect() function included biodiv_model_K10 topic model object.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_effect_K10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An STM regression object for a topic model with 10 topics — biodiv_effect_K10","text":"","code":"biodiv_effect_K10"},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_effect_K10.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An STM regression object for a topic model with 10 topics — biodiv_effect_K10","text":"STM regression object","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_model_K10.html","id":null,"dir":"Reference","previous_headings":"","what":"An STM topic model with 10 topics — biodiv_model_K10","title":"An STM topic model with 10 topics — biodiv_model_K10","text":"package data set provides sample STM topic model K = 10 topics (see stm::stm()). model fit bioRxiv medRxiv preprints 2017 2021 contain term 'biodiversity' title abstract. model fit respective publication status publication year topic prevalence covariates. included biodiv_effect_K10 dataset captures regression parameters document covariates.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_model_K10.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An STM topic model with 10 topics — biodiv_model_K10","text":"","code":"biodiv_model_K10"},{"path":"https://sdaume.github.io/srcquantcourse/reference/biodiv_model_K10.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An STM topic model with 10 topics — biodiv_model_K10","text":"STM topic model object","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_effect_K20.html","id":null,"dir":"Reference","previous_headings":"","what":"An STM regression object for a topic model with 20 topics — covid_effect_K20","title":"An STM regression object for a topic model with 20 topics — covid_effect_K20","text":"package data set provides results applying stm::estimateEffect() function included covid_model_K20 topic model object.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_effect_K20.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An STM regression object for a topic model with 20 topics — covid_effect_K20","text":"","code":"covid_effect_K20"},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_effect_K20.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An STM regression object for a topic model with 20 topics — covid_effect_K20","text":"STM regression object","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_model_K20.html","id":null,"dir":"Reference","previous_headings":"","what":"An STM topic model with 20 topics — covid_model_K20","title":"An STM topic model with 20 topics — covid_model_K20","text":"package data set provides sample STM topic model K = 20 topics (see stm::stm()). model fit bioRxiv medRxiv preprints 2020 2023 contain terms 'sars-cov' 'covid' title abstract. model fit respective preprint server publication year topic prevalence covariates. included covid_effect_K20 dataset captures regression parameters document covariates.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_model_K20.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"An STM topic model with 20 topics — covid_model_K20","text":"","code":"covid_model_K20"},{"path":"https://sdaume.github.io/srcquantcourse/reference/covid_model_K20.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"An STM topic model with 20 topics — covid_model_K20","text":"STM topic model object","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/srcquantcourse-package.html","id":null,"dir":"Reference","previous_headings":"","what":"srcquantcourse: Scripts and Exercises for the SRC Quantitative Methods PhD Course — srcquantcourse-package","title":"srcquantcourse: Scripts and Exercises for the SRC Quantitative Methods PhD Course — srcquantcourse-package","text":"package collects scripts, data exercises notes 2024 SRC Quantitative Methods PhD course.","code":""},{"path":[]},{"path":"https://sdaume.github.io/srcquantcourse/reference/srcquantcourse-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"srcquantcourse: Scripts and Exercises for the SRC Quantitative Methods PhD Course — srcquantcourse-package","text":"Maintainer: Stefan Daume stefan.daume@su.se (ORCID)","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/topicmodel_evaluations.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluation results for topic models with different K — topicmodel_evaluations","title":"Evaluation results for topic models with different K — topicmodel_evaluations","text":"convenience dataset include results evaluating topic models different topic numbers (K) thematic subsets bioRxiv medRxiv preprints. Scripts run actual evaluations included package repo.","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/topicmodel_evaluations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluation results for topic models with different K — topicmodel_evaluations","text":"","code":"topicmodel_evaluations"},{"path":"https://sdaume.github.io/srcquantcourse/reference/topicmodel_evaluations.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Evaluation results for topic models with different K — topicmodel_evaluations","text":"dataframe four variables","code":""},{"path":"https://sdaume.github.io/srcquantcourse/reference/topicmodel_evaluations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluation results for topic models with different K — topicmodel_evaluations","text":"dataset specifies preprint subset, used K, type evaluation metric value metric.","code":""}]
